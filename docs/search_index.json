[["index.html", "vignette 1 Status", " vignette 1 Status This status report outlines the code we are developing to process WinCruz data and prepare it for density estimation analysis using distance and related packages in R. Changes New status report format (a bookdown vignette, compatible with a future website and PDF tutorial.) Initiation of package framework (more efficient to design, develop, test, and document code). See Install chapter for details. Implementation of new settings system: survey-wide and cohort-specific settings. See Settings chapter for description / explanation. Update of strata and segmentizing functions to accommodate new settings system. See Processing chapter. The function process_polygon() now calculates the area, in km2, of strata and study area polygons. Next focus Transfer code to the new settings system and package framework: — mapping functions — sightings processing — survey summary Update backlog Back to developing the sightings processing Questions for Amanda Lots of structural changes (new vignette system, initiation of package framework). Lots on my list to do to complete the transfer, so not many questions for now. Am I getting closer with the new settings / segmentizing frameworks? "],["install.html", " 2 Install LTabundR Option 1: Install from GitHub Option 2: Install locally", " 2 Install LTabundR Option 1: Install from GitHub Since the package is currently private, this is more complicated than it will be once the package is released. The first step is creating an R environment variable containing your GitHub personal access token. Complete these instructions only once: # Open your .Renviron file library(usethis) usethis::edit_r_environ() # Add your GitHub personal access token as a variable in `.Renviron` GITHUB_TOKEN &lt;- &#39;your_token_goes_here_as_a_character_string&#39; # Save and close your .Renviron file # Reload .Renviron readRenviron(&#39;~/.Renviron&#39;) Then run this code every time you want to reinstall / update the package: library(devtools) github_token &lt;- Sys.getenv(&quot;GITHUB_TOKEN&quot;) devtools::install_github(repo = &#39;amandalbradford/LTabundR-dev&#39;, subdir=&#39;LTabundR&#39;, auth_token=github_token) library(LTabundR) Option 2: Install locally For now you can also install or update the package locally, using this code: library(devtools) # Remove the package, if you have an earlier version of it on your machine if(&#39;LTAabundR&#39; %in% installed.packages()){remove.packages(&#39;LTabundR&#39;)} # Specify the path to the package&#39;s project folder. path_to_package &lt;- &#39;../LTabundR&#39; # Update function documentation document(path_to_package) # Install package and any dependencies you need install(path_to_package) library(LTabundR) "],["settings.html", " 3 Settings Survey strata Study area polygon Survey-wide settings Cohort-specific settings Example code", " 3 Settings To customize the way data are processed and included in your analysis, use the load_settings() function. This function emulates and expands upon the settings file, ABUND.INP, that was used to run ABUND7/9 in FORTRAN. This function allows you to use ‘factory defaults’ if you don’t wish to specify anything special such as strata or study area polygons: settings &lt;- load_settings() If you do not want to use all the defaults, you can give load_settings() some custom inputs. The function accepts four arguments: strata: dataframe(s) of coordinates study_area: a dataframe of coordinates survey: settings that will apply universally to the analysis cohorts: settings that are specific to groups of species. By providing cohort-specific settings, the code for a single analysis becomes fully flexible to prepare and more easily reproduced, since code need not be modified in order to replicate the analysis in full. The output of load_settings() is a named list with a slot for each of these arguments: settings %&gt;% names [1] &quot;strata&quot; &quot;study_area&quot; &quot;survey&quot; &quot;cohorts&quot; Survey strata Stratum polygons can be provided as a named list of data.frame objects. Each data.frame must have Lat and Lon as the first two columns, providing coordinates in decimal degrees in which South and West coordinates are negative. Other columns are allowed, but the first two need to be Lon and Lat. The name of the slot holding the data.frame will be used as a reference name for the stratum. If strata is NULL, abundance will not be estimated; only density within the searched area (i.e., the total segment length x effective strip width). While users are welcome to upload polygons of their own, the package comes with “stock” polygons for strata that are commonly used in the main NMFS study regions: the Central North Pacific (CNP, including Hawaii) … data(strata_cnp) names(strata_cnp) [1] &quot;HI_EEZ&quot; &quot;WHICEAS&quot; &quot;OtherCNP&quot; …the California Current System (CCS) … data(strata_ccs) names(strata_ccs) [1] &quot;CCS&quot; &quot;Southern_CA&quot; &quot;Central_CA&quot; &quot;Nothern_CA&quot; &quot;OR_WA&quot; … and the Eastern Tropical Pacific (ETP): data(strata_etp) names(strata_etp) [1] &quot;MOPS_AreaCoreM&quot; &quot;MOPS_AreaIn&quot; &quot;MOPS_AreaIn1&quot; [4] &quot;MOPS_AreaIn2&quot; &quot;MOPS_AREAINS&quot; &quot;MOPS_AREAMID&quot; [7] &quot;MOPS_AreaMid1&quot; &quot;MOPS_AreaMid2&quot; &quot;MOPS_AreaMOPS&quot; [10] &quot;MOPS_AREANORS&quot; &quot;MOPS_AreaOuterM&quot; &quot;MOPS_AreaSou&quot; [13] &quot;MOPS_AREASOUS&quot; &quot;MOPS_AreaSpin&quot; &quot;MOPS_AreaSpinS&quot; [16] &quot;MOPS_AREAWES&quot; &quot;PODS_93STRAT1&quot; &quot;PODS_93STRAT2&quot; [19] &quot;PODS_Area92&quot; &quot;PODS_AREA92RS&quot; &quot;PODS_Area92s&quot; [22] &quot;PODS_AREA93&quot; &quot;PODS_AREA93A&quot; &quot;PODS_AREA93AR&quot; [25] &quot;PODS_AREA93AS&quot; &quot;PODS_AREA93BR&quot; &quot;PODS_AREA93M&quot; [28] &quot;PODS_AREA93MS&quot; &quot;PODS_AREA93R&quot; &quot;PODS_AREA93R1&quot; [31] &quot;PODS_AREA93R2&quot; &quot;PODS_AREA93RS&quot; &quot;PODS_AREA93S&quot; [34] &quot;PODS_AREANCOR&quot; &quot;PODS_GOCpoly&quot; &quot;Pre1986_Area79ES1&quot; [37] &quot;Pre1986_Area79ES1s&quot; &quot;Pre1986_Area79ES2&quot; &quot;Pre1986_Area79ES2s&quot; [40] &quot;Pre1986_Area79NE1&quot; &quot;Pre1986_Area79NE1s&quot; &quot;Pre1986_Area79NE2&quot; [43] &quot;Pre1986_Area79NE2s&quot; &quot;Pre1986_Area79NE3&quot; &quot;Pre1986_Area79NE3s&quot; [46] &quot;Pre1986_AreaCal&quot; &quot;Pre1986_AreaCals&quot; &quot;Pre1986_AreaMid&quot; [49] &quot;Pre1986_AreaMidS&quot; &quot;Pre1986_AreaNorth&quot; &quot;Pre1986_AreaNorthS&quot; [52] &quot;Pre1986_AreaSouth&quot; &quot;Pre1986_AreaSouthS&quot; &quot;STAR_Area98a&quot; [55] &quot;STAR_Area98b&quot; &quot;STAR_AreaCore&quot; &quot;STAR_AreaCore2&quot; [58] &quot;STAR_AreaCoreS&quot; &quot;STAR_AreaNCoast&quot; &quot;STAR_AreaNCstS&quot; [61] &quot;STAR_AreaOuter&quot; &quot;STAR_AreaOuter00&quot; &quot;STAR_AreaSCoast&quot; [64] &quot;STAR_AreaSCstS&quot; &quot;STAR_AreaSPn&quot; &quot;STAR_AreaSPs&quot; [67] &quot;STAR_AreaSTAR&quot; &quot;STAR_AreaSTAR2&quot; &quot;STAR_AreaSTARlite&quot; [70] &quot;STAR_Dcaparea&quot; The package includes functions for visualizing and selecting from these strata. See the Strata Gallery appendix. Study area polygon The study_area argument accepts a single data.frame, formatted the same as those for the strata argument, or a numeric value indicating the area of your study area in square km. If study_area is NULL, abundance will not be estimated; only density. Study area polygons can be provided in the same format as strata: a two-column csv (column names Lon and Lat with decimal-degree coordinates). A stock study area polygon is available for the CNP: data(study_cnp) study_cnp Lon Lat 1 -131 40.00 2 -126 32.05 3 -120 25.00 4 -120 -5.00 5 -185 -5.00 6 -185 40.00 7 -131 40.00 Survey-wide settings Survey-wide settings apply universally to all species in the analysis. Defaults settings$survey $segment_method [1] &quot;day&quot; $segment_target_km [1] 150 $segment_max_km_gap [1] 5 $segment_max_interval [1] 48 $segment_type_handling [1] &quot;separate&quot; &quot;pool&quot; $segment_remainder_handling [1] &quot;append&quot; &quot;segment&quot; $ship_list NULL $species_codes NULL $group_size_coefficients NULL $smear_angles [1] FALSE $random_seed [1] 833171 $verbose [1] TRUE Defaults for the survey argument list are built up efficiently using the function load_survey_settings() (see example code at bottom). Details The survey_settings input accepts a list with any of the following named slots: segment_method: this argument controls how effort will be “segmentized”, or chopped into discrete sections for the purposes of estimating the variance of the abundance estimate. The two options are \"day\" – all effort within the same Cruise-StudyArea-Stratum-Year-Effort will be binned into segments by calendar date – and \"equallength\" – effort within each unique effort scenario (Cruise-StudyArea-etc.) will be divided into segments of approximately equal length. segment_target_km: if segmenting by \"equallength\", this field allows you to specify what that target length is, in km. segment_max_km_gap: the segmentizing function works by calculating the distance between each row of DAS data. If that distance exceeds the length specified here (e.g., 5 km), the function will assume that there was a break in effort. segment_max_interval: if segmentizing by \"equallength\", this setting allows you to specify the time gaps in effort contained within a single segment. For example, if your goal is a few large segments of equal length (e.g., 150-km segments, for bootstrap estimation of density variance), you are probably willing for discrete periods of effort to be concatenated into a single segment, even if the gaps between effort are as large as 1 or 2 days, in which case you would set segment_max_interval to 24 or 48 (hours), respectively. However, if your goal is many smaller segments (e.g., 5-km segments, for habitat modeling), you want to ensure that effort is contiguous so that segment locations can be accurately related to environmental variables, in which case you would set segment_max_interval to be very small (e.g., .1 or 6 minutes). segment_type_handling: if \"pool\", all effort types that qualify as valid according to cohort_settings (see next section) will be pooled together, making it possible for different effort types to occur in the same segment (e.g., EffType’s “S” and “F” are allowed to occur in the same segment; if this argument is \"separate\", segments will only be allowed to contain a single effort type. segment_remainder_handling: if segmentizing by \"equallength\", periods of contiguous effort (as specified by segment_max_interval) are unlikely to be perfectly divisible by your segment_target_km; there is going to be a remainder. You can handle this remainder in various ways: (1) \"disperse\" allows the function to adjust segment_target_km so that there is in fact no remainder, effectively dispersing the remainder evenly across all segments within that period of contiguous effort; (2) \"append\" asks the function to append the remainder to a randomly selected segment; (3) \"segment\" asks the function to simply place the remainder in its own segment, placed randomly within the period of contiguous effort. Note that this setting has a second layer of versatility, because it can accept a one- or two-element character vector. If a two-element vector is provided (e.g., c(\"append\",\"segment\")), the first element will be used in the event that the remainder is less than or equal to half segment_target_km; if the remainder is more than half that target length, the second element will be used. This feature allows for replication of the segmentizing methods in Becker et al. (2010). ship_list: A data.frame containing a list of ship names. If not provided the default version, which was current as of the release of ABUND9 in 2020, will be used (data(ships)). Supplied data.frames must match the column naming structure of data(ships). (Note: the purpose of this argument in the INP file is not clear to me; need to understand how/why to include this. – eric) species_codes: A data.frame containing species codes. If not provided the default version, which was current as of the release of ABUND9 in 2020, will be used (data(species_codes)). Supplied data.frames must match the column naming structure of data(species_codes). group_size_coefficients: A data.frame of calibration factors. NOTE: details needed here. smear_angles: If TRUE (the default is FALSE), bearing angles to a group of animals will be “smeared” by adding a uniformly distributed random number between -5 and +5 degrees. This has not been used in any recent analyses because observers have not been rounding angles as much. It was suggested by Buckland as a method for dealing with rounding which is especially influential when rounding to zero places many sightings at zero perpendicular distance. random_seed: a number used as the seed for stages involving random number generation. If not NULL, the results will be exactly reproducible. Default is 833171 (sensu example code in ABUND9). verbose: If TRUE (the default), status updates will be printed to the R console. Cohort-specific settings Cohort-specific settings apply only to a group of species. Defaults The default is to use a single cohort for all species: settings$cohorts %&gt;% names [1] &quot;default&quot; Default values for the default cohort: settings$cohorts$default $id [1] &quot;default&quot; $species NULL $probable_species [1] FALSE $sighting_method [1] 0 $cue_range [1] 0 1 2 3 4 5 6 7 $school_size_range [1] 0 10000 $use_low_if_na [1] FALSE $io_sightings [1] 0 $geometric_mean_group [1] TRUE $truncation_km [1] 5.5 $beaufort_range [1] 0 1 2 3 4 5 6 $abeam_sightings [1] FALSE $strata_overlap_handling [1] &quot;smallest&quot; &quot;largest&quot; &quot;each&quot; $density_types [1] &quot;S&quot; &quot;F&quot; $density_modes [1] &quot;P&quot; &quot;C&quot; $density_on_off [1] TRUE $distance_types NULL $distance_modes NULL $distance_on_off [1] TRUE Defaults for the cohorts argument list is built up efficiently using the function load_cohort_settings() (see example code at bottom). Details The cohort_settings input accepts a list of any length. Each slot in that list can contain settings for a different cohort. Each cohort list can have any of the following named slots: id: An informal identifier for this cohort, to help you keep track of which cohort is which. For example, settings for a cohort of large whales species could be named \"big whales\"; settings for small delphinids and phocoenids could be named \"small_odontocetes\"; settings for beaked whales could be named \"beakers\". species: A vector of species codes to include in this cohort. If NULL (the default), all species will be included. probable_species: If TRUE (default is FALSE), the “probable” species identifications will be used in place of the “unidentified” categories. The probable species codes are marked with an event code “?” in the data file following the “S” and “A” event codes of a sighting. sighting_method: A coded integer which determines which sightings will be included based on how they were first seen. Allowable codes are 0=any method, 1=with 25X only, 2=not with 25X binos and not from helo (ie. naked eyes and 7x). cue_range: Numeric vector of acceptable “observation cues” for sightings used in estimates of abundance. (0=MISSNG, 1=BRD, 2=SPLSH, 3=MAMM, 4=SHIP, 5=?, 6=BLOW, 7=HELO) school_size_range: Minimum and maximum group sizes to be included in estimates of abundance. This is the overall group size, not the number of the given species that are present in a group. use_low_if_na: If an observer does not make a best estimate of group size, mean group size will be calculated from “low” estimates. This will be done only if no observer has a “best” estimate. io_sightings: A coded integer which specifies how sightings by the independent observer will be handled. Allowable codes are _1=include independent observer sightings wih all other sightings, 0=ignore sightings by independent observer, 1=use only sightings made by regular observer team WHEN an independent observer was present, 2=include only sightings made by the independent observer. Used for making g(0) estimates only, otherwise IO sightings are usually ignored (code = 0). geometric_mean_group: This logical variable specifies whether to use a weighted geometric mean when calculating mean group size. Barlow, Gerrodette, and Perryman (1998) found that this gave slightly better performance than a straight mean group size. Default is TRUE. truncation_km: Specifies the maximum perpendicular distance for groups that are to be included for abundance estimation. Also determines the bins used for grouped perpendicular distances. beaufort_range: Vector of Beaufort sea states (integers) that are acceptable in estimating the detection function and density. Beaufort data with a decimal place will be rounded to the nearest integer to evaluate for inclusion. abeam_sightings: = If TRUE, sightings that occur aft of beam are included in estimating the detectin function and densities. Default is FALSE: all abeam sightings will be ignored. strata_overlap_handling: In the event that survey strata overlap, this setting tells R how to handle it. The options are \"smallest\" (the default), in which effort can belong to only a single stratum, and the smallest of overlapping strata will be used (e.g., an insular polygon nested within a larger EEZ polygon); \"largest\", in which effort can belong to only a single stratum and the largest of overlapping strata will be used (we are not sure what use case this would server, but we offer it as an option for niche analyses); and \"each\", in which each effort is allowed to belong to two or more strata at once and all analyses will be conducted for each overlapping polygon separately (e.g., this may be appropriate for nested strata in which you want to estimate density in the entirety of the larger stratum in addition to estimating density for the nested stratum). density_types: A character vector of the effort types that will be included in detection function estimation and density estimation, and therefore considered in effort segmentizing. Accepted values are \"S\" (systematic/standard effort), \"F\" (fine-scale effort), and \"N\" (non-systematic/non-standard effort, in which systematic protocols are being used but effort is not occurring along design-based transect routes). The default values are c(\"S\",\"F\"). density_modes: The effort modes that will be included in detection function estimation and density estimation, and therefore considered in effort segmentizing. Accepted values are \"P\" (passing) and \"C\" (closing), and the default values are c(\"P\",\"C\"). density_on_off: The value(s) of OnEffort (On Effort is TRUE, Off Effort is FALSE) that will included in detection function estimation and density estimation, and therefore considered in effort segmentizing. Default is TRUE only. distance_types: If effort types are specified in this argument, this selection will be used to filter data for estimation of the detection function. If left NULL (the default), the argument density_types will be used. This option will be rarely used, but it may prove helpful in cases in which sightings for a species are so few that including all effort types (c('S','F','N')) may be justifiable for estimating the detection function, even if only 'S' and 'F' are used for density estimation. distance_modes: Same idea as distance_types above, but for effort modes (Passing / Closing). distance_on_off: Same idea as distance_types above, but for OnEffort status (TRUE or FALSE). Example code Use settings defaults (no strata) settings &lt;- load_settings() Use settings defaults with strata # Load strata dataframes data(strata_cnp) data(study_cnp) settings &lt;- load_settings(strata = strata_cnp, study_area = study_cnp) Customize survey, but not cohorts When a cohort is not specified, the default values will be used. # Load strata dataframes data(strata_cnp) data(study_cnp) # Survey settings survey &lt;- load_survey_settings(segment_method = &#39;equallength&#39;, segment_target_km = 30, segment_max_km_gap = 5, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), verbose = TRUE) # Load settings settings &lt;- load_settings(strata = strata_cnp, study_area = study_cnp, survey) Fully custom: strata, study area, survey and cohorts These are the settings we will use in the remainder of the tutorial: # Load strata data(strata_cnp) data(study_cnp) # Survey settings survey &lt;- load_survey_settings(segment_method = &#39;equallength&#39;, segment_target_km = 30, segment_max_km_gap = 5, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), verbose = TRUE) # Cohort 1 (default) cohort1 &lt;- load_cohort_settings() # Cohort 2 cohort2 &lt;- load_cohort_settings(id=&#39;fkw_insular&#39;, species=33, use_low_if_na = TRUE, truncation_km = 5, strata_overlap_handling = &#39;each&#39;) # Load settings settings &lt;- load_settings(strata = strata_cnp, study_area = study_cnp, survey = survey, cohorts=list(cohort1, cohort2)) "],["processing.html", " 4 Data processing Bring in cruise data Format DAS data Process strata Segmentize the data Process sightings", " 4 Data processing Bring in cruise data Specify the path to your .DAS data file(s): das_file &lt;- &#39;data/surveys/HICEASwinter2020.das&#39; Read in and process this .DAS file using the functions in Sam’s swfscDAS package. To do so quickly, we built a wrapper function that makes this quick and easy: das &lt;- load_das(das_file, perform_checks = TRUE, print_glimpse = TRUE) Cruise numbers: 2001 &lt;NA&gt; 48 0 Rows: 22,486 Columns: 40 $ Event &lt;chr&gt; &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;B&quot;, &quot;R&quot;, … $ DateTime &lt;dttm&gt; 2020-01-19 07:11:52, 2020-01-19 07:13:52, 2020-01-19 07:15:… $ Lat &lt;dbl&gt; 21.79983, 21.80517, 21.81050, 21.81583, 21.82133, 21.82667, … $ Lon &lt;dbl&gt; -159.7652, -159.7657, -159.7662, -159.7668, -159.7673, -159.… $ OnEffort &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS… $ Cruise &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2001, 2001, 2001, 20… $ Mode &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, … $ OffsetGMT &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, -10, -10, -10, -10, … $ EffType &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;… $ ESWsides &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, 2, 2, 2, 2, 2… $ Course &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 350,… $ SpdKt &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 9.9,… $ Bft &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4, 4, 4,… $ SwellHght &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 6, 6, 6,… $ WindSpdKt &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 15, 15, … $ RainFog &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ HorizSun &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ VertSun &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Glare &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Vis &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ ObsL &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;126&quot;, &quot;126&quot;… $ Rec &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;307&quot;, &quot;307&quot;… $ ObsR &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;238&quot;, &quot;238&quot;… $ ObsInd &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data1 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;2001&quot;, &quot;F&quot;, &quot;126&quot;, … $ Data2 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;C&quot;, NA, &quot;307&quot;, &quot;06&quot;… $ Data3 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;-10&quot;, NA, &quot;238&quot;, &quot;1… $ Data4 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;N&quot;, NA, NA, NA, NA,… $ Data5 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;15.0&quot;, … $ Data6 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data7 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data8 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data9 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data10 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data11 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data12 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ EffortDot &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS… $ EventNum &lt;chr&gt; &quot;001&quot;, &quot;002&quot;, &quot;003&quot;, &quot;004&quot;, &quot;005&quot;, &quot;006&quot;, &quot;007&quot;, &quot;008&quot;, &quot;009… $ file_das &lt;chr&gt; &quot;HICEASwinter2020.das&quot;, &quot;HICEASwinter2020.das&quot;, &quot;HICEASwinte… $ line_num &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1… Format DAS data Finalize formatting: remove rows with invalid locations and calculate the distance, in km, between each row of data. Other refinements can be added to this function later on. das &lt;- format_das(das, settings) par(mfrow=c(1,2)) hist(das$km_int, xlab=&#39;KM between each DAS row&#39;, main=NULL, breaks=seq(0,max(das$km_int),length=100)) plot(das$km_cum, ylab=&#39;Cumulative KM surveyed&#39;, main=NULL, type=&#39;l&#39;) Process strata Run the following function to add strata and study-area information to each sub-segment of effort: cruz &lt;- process_strata(das, settings) Spherical geometry (s2) switched off This function loops through each stratum data.frame you have provided it in settings$strata, formats the stratum, and asks whether each DAS row occurs within it. For each stratum, a column named stratum_&lt;StratumName&gt; is added to the das object; each row in this column is TRUE (included) or FALSE. A similar procedure is run if a dataframe is provided in settings$study_area. A column named study_area is added to das containing a boolean (TRUE if the sub-segment or sighting occurs within the study area). The function then loops through each species cohort and uses that cohort’s settings to determine a single stratum assignment for each row of DAS data in the event of overlapping strata. The key cohort setting referenced here is stratum_overlap_handling. The cruz object The function process_strata() returns a list, which we have saved in an object named cruz, with several slots: cruz %&gt;% names [1] &quot;das&quot; &quot;settings&quot; &quot;strata&quot; &quot;study_area&quot; &quot;cohorts&quot; The slots strata and study_area provide the area, in square km, of each polygon being used: cruz$strata stratum area 1 HI_EEZ 2491447.3 2 WHICEAS 419789.2 3 OtherCNP 34232739.5 cruz$study_area [1] 34232739 The slot cohorts is itself a list with one slot for each cohort. The slots are named using the id cohort setting. cruz$cohorts %&gt;% names [1] &quot;default&quot; &quot;fkw_insular&quot; Each cohort slot has a copy of the DAS data with a stratum assignment tailored to its cohort-specific settings. For instance, the default cohort, whose stratum_overlap_handling is set to \"smallest\", assigns the smallest stratum in the event of overlapping or nested strata: cruz$cohorts$default$stratum %&gt;% table(useNA=&#39;ifany&#39;) . HI_EEZ WHICEAS 142 22228 The fkw_insular cohort, whose stratum_overlap_handling is set to \"each\" (i.e., effort is allowed to belong to multiple segments, if they overlap, and all analyses will be conducted for each stratum separately), has stratum assignments that look like this; cruz$cohorts$fkw_insular$stratum %&gt;% table(useNA=&#39;ifany&#39;) . HI_EEZ&amp;OtherCNP HI_EEZ&amp;WHICEAS&amp;OtherCNP 142 22228 When a row of DAS effort occurs in two overlapping strata, the stratum assignment for that row is a concatentation of the names of the strata it falls within, with names separated by “&amp;”. This list, with these five primary slots, will be referred to as a cruz object. The remainder of the data processing work flow is focused upon refining the effort and sighting data for each slot in cohorts. The other slots are no longer modified. Segmentize the data To allocate survey data into discrete ‘effort segments’, which are used in variance estimation in subsequent steps, run the function segmentize(). This process is controlled by both survey-wide and cohort-specific settings, which are now carried in a slot within the cruz object. cruz &lt;- segmentize(cruz, verbose=TRUE) [1] &quot;separate&quot; [1] &quot;append&quot; &quot;segment&quot; [1] &quot;equallength&quot; [1] 833171 [1] 172800 [1] 30 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;separate&quot; [1] &quot;append&quot; &quot;segment&quot; [1] &quot;equallength&quot; [1] 833171 [1] 172800 [1] 30 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; &quot;N&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE This function does not change the high-level structure of the cruz object … cruz %&gt;% names [1] &quot;das&quot; &quot;settings&quot; &quot;strata&quot; &quot;study_area&quot; &quot;cohorts&quot; … or the cohort names in the cohorts slot … cruz$cohorts %&gt;% names [1] &quot;default&quot; &quot;fkw_insular&quot; But it does change the structure of data within each cohort. Each cohort will now have a slot named density … cruz$cohorts$default %&gt;% names [1] &quot;density&quot; And, if your settings specify that settings for density estimation differ from detection function estimation, a cohort will have a second slot named distance. This is the case for the second cohort in our example analysis: fkw_insular. cruz$cohorts$fkw_insular %&gt;% names [1] &quot;density&quot; &quot;distance&quot; Though their data segmentization will differ, the density and distance slots have identical structures: cruz$cohorts$fkw_insular$density %&gt;% names [1] &quot;segments&quot; &quot;effort&quot; &quot;das&quot; cruz$cohorts$fkw_insular$distance %&gt;% names [1] &quot;segments&quot; &quot;effort&quot; &quot;das&quot; The segments slot contains summary data for each effort segment, including start/mid/end coordinates, average conditions, and segment distance: cruz$cohorts$default$density$segments %&gt;% glimpse Rows: 278 Columns: 36 $ Cruise &lt;dbl&gt; 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 200… $ stratum &lt;chr&gt; &quot;HI_EEZ&quot;, &quot;HI_EEZ&quot;, &quot;HI_EEZ&quot;, &quot;HI_EEZ&quot;, &quot;HI_EEZ&quot;, &quot;WHICEA… $ study_area &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU… $ seg_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… $ yday &lt;dbl&gt; 21, 22, 39, 68, 22, 19, 19, 19, 20, 20, 21, 22, 23, 23, 2… $ dist &lt;dbl&gt; 3.2237470, 0.6118778, 29.7257476, 19.8973176, 1.2231556, … $ lat1 &lt;dbl&gt; 22.33300, 22.68750, 20.79283, 21.65833, 22.68750, 21.8520… $ lon1 &lt;dbl&gt; -161.2520, -161.1208, -153.6117, -161.7810, -161.1208, -1… $ DateTime1 &lt;dttm&gt; 2020-01-21 07:28:48, 2020-01-22 07:42:01, 2020-02-08 06:… $ timestamp1 &lt;dbl&gt; 1579591728, 1579678921, 1581144814, 1583688255, 157967892… $ lat2 &lt;dbl&gt; 22.68750, 20.79217, 21.65683, 21.66717, 22.68617, 22.1771… $ lon2 &lt;dbl&gt; -161.1208, -153.6090, -161.7753, -161.9295, -161.1158, -1… $ DateTime2 &lt;dttm&gt; 2020-01-22 07:42:01, 2020-02-08 06:51:34, 2020-03-08 17:… $ timestamp2 &lt;dbl&gt; 1579678921, 1581144694, 1583688135, 1583692815, 157967903… $ mlat &lt;dbl&gt; 22.69117, 20.79133, 21.62583, 21.68417, 22.68750, 22.2345… $ mlon &lt;dbl&gt; -161.1353, -153.6063, -161.6553, -161.8822, -161.1208, -1… $ mDateTime &lt;dttm&gt; 2020-01-22 07:31:52, 2020-02-08 06:49:34, 2020-03-08 16:… $ mtimestamp &lt;dbl&gt; 1579591728, 1579678921, 1581144814, 1583688255, 157967892… $ use &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FA… $ Mode &lt;chr&gt; NA, &quot;P&quot;, NA, &quot;C&quot;, &quot;P&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, NA, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, … $ EffType &lt;chr&gt; NA, &quot;S&quot;, NA, &quot;S&quot;, &quot;S&quot;, NA, &quot;N&quot;, &quot;F&quot;, NA, &quot;S&quot;, &quot;F&quot;, &quot;S&quot;, &quot;… $ ESWsides &lt;dbl&gt; NA, 2, NA, 2, 2, NA, 2, 2, NA, 2, 2, 2, 2, 2, NA, 2, 2, 2… $ year &lt;dbl&gt; 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020, 202… $ month &lt;dbl&gt; 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … $ day &lt;int&gt; 21, 22, 8, 8, 22, 19, 19, 19, 20, 20, 21, 22, 23, 23, 24,… $ min_line &lt;int&gt; 1080, 1549, 9811, 20825, 1550, 11, 240, 601, 701, 963, 14… $ max_line &lt;int&gt; 1548, 9810, 20824, 20886, 1554, 239, 499, 700, 962, 1486,… $ n_rows &lt;int&gt; 14, 3, 58, 62, 5, 103, 120, 99, 111, 164, 117, 89, 90, 59… $ avgBft &lt;dbl&gt; NaN, NaN, 7.000000, 6.418047, 2.000000, 5.150894, 4.84389… $ avgSwellHght &lt;dbl&gt; NaN, NaN, 7.000000, 7.000000, 4.000000, 7.433929, 7.20666… $ avgHorizSun &lt;dbl&gt; NaN, NaN, 10.958794, 11.000000, NaN, 6.954993, 6.314060, … $ avgVertSun &lt;dbl&gt; NaN, NaN, 1.058675, 2.418106, NaN, 1.419236, 1.178142, 2.… $ avgGlare &lt;dbl&gt; NaN, NaN, 0.05867486, 1.00000000, NaN, 0.00000000, 0.4734… $ avgVis &lt;dbl&gt; 4.000000, NaN, 5.000000, 4.709023, 6.200000, 5.641518, 6.… $ avgCourse &lt;dbl&gt; NaN, NaN, 287.23315, 269.55972, 105.00000, 247.16155, 166… $ avgSpdKt &lt;dbl&gt; NaN, NaN, 9.968032, 9.315076, 9.000000, 8.964329, 8.18859… # Number of segments cruz$cohorts$default$density$segments %&gt;% nrow [1] 278 # Segment length distribution hist(cruz$cohorts$default$density$segments$dist, breaks = seq(0,60,by=1), xlab=&#39;Segment lengths (km)&#39;, main=paste0(&#39;Target km: &#39;,settings$survey$segment_target_km)) The effort slot is itself a list in which each slot holds the DAS for a single segment. cruz$cohorts$default$density$effort %&gt;% length [1] 278 And the das slot holds the original data.frame of DAS data, modified slightly: the column OnEffort has been modified according to Beaufort range conditions, and the column seg_id indicates which segment the event occurs within cruz$cohorts$default$density$das %&gt;% names [1] &quot;Event&quot; &quot;DateTime&quot; &quot;Lat&quot; &quot;Lon&quot; [5] &quot;OnEffort&quot; &quot;Cruise&quot; &quot;Mode&quot; &quot;OffsetGMT&quot; [9] &quot;EffType&quot; &quot;ESWsides&quot; &quot;Course&quot; &quot;SpdKt&quot; [13] &quot;Bft&quot; &quot;SwellHght&quot; &quot;WindSpdKt&quot; &quot;RainFog&quot; [17] &quot;HorizSun&quot; &quot;VertSun&quot; &quot;Glare&quot; &quot;Vis&quot; [21] &quot;ObsL&quot; &quot;Rec&quot; &quot;ObsR&quot; &quot;ObsInd&quot; [25] &quot;Data1&quot; &quot;Data2&quot; &quot;Data3&quot; &quot;Data4&quot; [29] &quot;Data5&quot; &quot;Data6&quot; &quot;Data7&quot; &quot;Data8&quot; [33] &quot;Data9&quot; &quot;Data10&quot; &quot;Data11&quot; &quot;Data12&quot; [37] &quot;EffortDot&quot; &quot;EventNum&quot; &quot;file_das&quot; &quot;line_num&quot; [41] &quot;year&quot; &quot;month&quot; &quot;day&quot; &quot;yday&quot; [45] &quot;km_int&quot; &quot;km_cum&quot; &quot;stratum_HI_EEZ&quot; &quot;stratum_WHICEAS&quot; [49] &quot;stratum_OtherCNP&quot; &quot;study_area&quot; &quot;stratum&quot; &quot;seg_id&quot; The segmentize() function and its associated settings were designed to give researchers full control over how data are segmented, be it for design-based density analysis (which tend to use long segments of 100 km or more and allow for non-contiguous effort to be included in the same segment) or for habitat modeling (which tend to use short segments of 5 - 10 km and disallow non-contiguous effort to be pooled into the same segment). To demonstrate that versatility, checkout the appendix on segmentizing. Process sightings Coming soon! "],["maps.html", " 5 Maps Base maps Add strata Add survey tracks Customizing effort", " 5 Maps To build a flexible system for mapping cruise data, we have the following functions: Base maps Begin with a basic map, including EEZ borders: m &lt;- map_base(region=&#39;cnp&#39;) m We also have a base map for the California Current … m &lt;- map_base(region=&#39;ccs&#39;) m And the ETP: m &lt;- map_base(region=&#39;etp&#39;) m Add strata Add your research strata to your map: m &lt;- map_base(region=&#39;cnp&#39;) m &lt;- map_strata(m, settings, region=&#39;cnp&#39;) m Add survey tracks Note: this may take a minute to render. m1 &lt;- map_effort(m, cruz) m1 The defaults of map_effort() assume, for simplicity, that you want to see the segments to be included in density estimation for the first cohort specified in your settings. You can adjust this and other defaults using the function arguments. Customizing effort Inputs To demonstrate some of the customization options, consider this map that shows segments to be excluded from the \"distance\" (detection function) analysis for our second cohort (fkw_insular). map_effort(m, cruz, cohort = 2, analysis = &#39;distance&#39;, use_type = c(FALSE), effort_color=&#39;firebrick&#39;, effort_stroke=2.5, effort_linetype=1,) Color-code conditions Your second customization option is to add format variables to the segments slot of the cohort of interest in the cruz object. This gives you full control of line color, thickness, and line-type according to whatever specifications you wish to set, e.g., color-coding by effort type or Beaufort sea state. This is possible because the function map_effort() looks for the variables col (line color), lwd (line thickness or stroke), and lty (line type) in the columns of cruz$segments. If these columns exist, the values therein will be used instead of the function defaults. For example, color-code by Beaufort scale: # Save copy of cruz object data to modify cruz2 &lt;- cruz segments &lt;- cruz2$cohorts$default$density$segments # Add column `col`: color code by BFT sea state bft_colors &lt;- c(&#39;steelblue4&#39;,&#39;steelblue2&#39;,&#39;cadetblue1&#39;,&#39;grey&#39;) segments$col &lt;- bft_colors[4] segments$col[ segments$avgBft &lt;= 7 ] &lt;- bft_colors[3] # bft 5 + segments$col[ segments$avgBft &lt;= 4 ] &lt;- bft_colors[2] # bft 3 - 4 segments$col[ segments$avgBft &lt;= 2 ] &lt;- bft_colors[1] # bft 0 -2 # Update sub_segments slot in `cruz` object cruz2$cohorts$default$density$segments &lt;- segments # Update map m_custom2 &lt;- map_effort(m, cruz2) # Add legend using native functions from mapping package `tmap` m_custom2 &lt;- m_custom2 + tmap::tm_add_legend(&#39;line&#39;, col = bft_colors, lwd = 3, labels = c(&#39; 0 - 2&#39;, &#39; 3 - 4&#39;, &#39; 5 +&#39;, &#39; no data&#39;), title=&quot;Beaufort sea state&quot;) + tmap::tm_layout(legend.position=c(&#39;left&#39;,&#39;bottom&#39;)) # Show map m_custom2 "],["summarize.html", " 6 Summarize survey", " 6 Summarize survey Coming soon! "],["df.html", " 7 Detection functions", " 7 Detection functions Coming soon! "],["abundance.html", " 8 Abundance estimation", " 8 Abundance estimation Coming soon! "],["casestudies.html", " 9 Case studies Central North Pacific California Current System Eastern Tropical Pacific", " 9 Case studies To demonstrate what we are building, below is template for quickly running all of the steps detailed in subsequent chapters. Central North Pacific This template use the same data and settings used throughout the vignette: library(LTabundR) # Settings ===================================================================== # Load strata &amp; study area data(strata_cnp) data(study_cnp) # Survey-wide survey &lt;- load_survey_settings(segment_method = &#39;equallength&#39;, segment_target_km = 30, segment_max_km_gap = 5, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), verbose = TRUE) # Cohort 1 (default) cohort1 &lt;- load_cohort_settings() # Cohort 2 cohort2 &lt;- load_cohort_settings(id=&#39;fkw_insular&#39;, species=33, use_low_if_na = TRUE, truncation_km = 5, strata_overlap_handling = &#39;each&#39;) # Finalize settings settings &lt;- load_settings(strata = strata_cnp, study_area = study_cnp, survey = survey, cohorts=list(cohort1, cohort2)) # Processing =================================================================== # Load &amp; format DAS das_file &lt;- &#39;data/surveys/HICEASwinter2020.das&#39; das &lt;- load_das(das_file, perform_checks = TRUE, print_glimpse = TRUE) das &lt;- format_das(das, settings) # Process strata cruz &lt;- process_strata(das, settings) # Sanity-check stratum assignments cruz$cohorts$default$stratum %&gt;% table(useNA=&#39;ifany&#39;) cruz$cohorts$fkw_insular$stratum %&gt;% table(useNA=&#39;ifany&#39;) # Segmentize cruz &lt;- segmentize(cruz, verbose=TRUE) # Review: Number of segments cruz$cohorts$default$density$segments %&gt;% nrow # Review: segment length distribution hist(cruz$cohorts$default$density$segments$dist, breaks = seq(0,60,by=1), xlab=&#39;Segment lengths (km)&#39;, main=paste0(&#39;Target km: &#39;,settings$survey$segment_target_km)) California Current System library(LTabundR) # Read in DAS data das_file &lt;- &#39;data/surveys/CAORWA_91-09.das&#39; das &lt;- load_das(das_file) # Subset to a single cruise das &lt;- das %&gt;% filter(Cruise == 1635) Eastern Tropical Pacific "],["practicalities.html", " 10 Practicalities", " 10 Practicalities Reproducibility &amp; project management One of the features of the ABUND framework we need to retain is that each analysis is self-contained and reproducible. The folder for an analysis must have all the files and data needed for someone else to be able to replicate it. In the R package framework we are developing, the contents of a project folder will be straightforward (once the code base is bundled into a package). Contents of a project folder: DAS file(s) with survey data Stratum and study area polygon(s), as csv(s) (optional) Group size calibration files (optional) An analysis.R file (or perhaps a .Rmd), containing an adaptation of the code provided in the template above. This script will contain project-specific settings (e.g., the load_settings() call), which allow for the script to be reproducible. "],["stratagallery.html", " 11 Appendix: Strata gallery Central North Pacific California Current ETP", " 11 Appendix: Strata gallery Central North Pacific strata_explore(&#39;cnp&#39;) To acquire the filepath to one of these strata, pass the index (or indices) printed in the map titles above to the function strata_select(): strata &lt;- strata_select(selections = c(1,3), region = &#39;cnp&#39;) This function returns a named list that can be passed directly to the strata argument in load_settings(). strata %&gt;% names [1] &quot;HI_EEZ&quot; &quot;OtherCNP&quot; The second slot, $paths, contains the filepaths you would need to pass to the load_settings() function. California Current strata_explore(&#39;ccs&#39;) ETP strata_explore(&#39;etp&#39;) "],["segmentizing.html", " 12 Appendix: Segmentizing Defaults Day vs Equal Length Contiguous vs. non-contiguous effort Segment remainder handling Typical settings", " 12 Appendix: Segmentizing The package’s segmentize() function and its associated settings were designed to give researchers full control over how data are segmented, be it for design-based density analysis (which tend to use long segments of 100 km or more and allow for non-contiguous effort to be included in the same segment) or for habitat modeling (which tend to use short segments of 5 - 10 km and disallow non-contiguous effort to be pooled into the same segment). The demonstration of segmentize() on in Processing chapter relies on the settings object that is attached as a slot in the cruz object. But you can override those settings with direct function inputs in segmentize(), which gives us a chance to explore segmentization options. First we loadthe demo data and carry out initial processing: data(settings) das_file &lt;- &#39;data/surveys/HICEASwinter2020.das&#39; das &lt;- load_das(das_file, perform_checks = FALSE, print_glimpse = FALSE) das &lt;- format_das(das, settings) cruz &lt;- process_strata(das, settings, verbose=FALSE) And this is the histogram function we will be using to display the results of each run of segmentize(): segment_histogram &lt;- function(cohort_effort, by_day=FALSE){ segs &lt;- cohort_effort$segments segmax &lt;- max(segs$dist,na.rm=TRUE)*1.1 if(by_day){ main_use &lt;- paste0(&#39;Segments (use) | by day&#39;) main_exclude &lt;- paste0(&#39;Segments (exclude) | by day&#39;) }else{ main_use &lt;- paste0(&#39;Segments (use) | target: &#39;,settings$survey$segment_target_km,&#39; km&#39;) main_exclude &lt;- paste0(&#39;Segments (exclude) | target: &#39;,settings$survey$segment_target_km,&#39; km&#39;) } par(mfrow=c(1,2)) par(mar=c(4.2,4.2,2.5,.5)) hist(segs$dist[segs$use], breaks = seq(0,segmax,by=segmax/40), xlab=&#39;Segment lengths (km)&#39;, main=main_use, cex.main = .8, cex.axis = .8, cex.lab = .8) hist(segs$dist[!segs$use], breaks = seq(0,segmax,by=segmax/40), xlab=&#39;Segment lengths (km)&#39;, main=main_exclude, cex.main = .8, cex.axis = .8, cex.lab = .8) par(mfrow=c(1,1)) } Defaults Here is the segmentize() function parameterized with the “factory default” settings from load_settings(). cruz_demo &lt;- segmentize(cruz, segment_method = &#39;equallength&#39;, segment_target_km = 30, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), density_types = c(&#39;S&#39;,&#39;F&#39;), density_modes = c(&#39;P&#39;,&#39;C&#39;), density_on_off = c(TRUE), distance_types = NULL, distance_modes = NULL, distance_on_off = NULL, random_seed = NULL) [1] &quot;separate&quot; [1] &quot;append&quot; &quot;segment&quot; [1] &quot;equallength&quot; [1] 833171 [1] 172800 [1] 30 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;separate&quot; [1] &quot;append&quot; &quot;segment&quot; [1] &quot;equallength&quot; [1] 833171 [1] 172800 [1] 30 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; &quot;N&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE # Number of segments cruz_demo$cohorts$default$density$segments %&gt;% nrow [1] 278 # Plot segment_histogram(cruz_demo$cohorts$default$density) Day vs Equal Length cruz_demo &lt;- segmentize(cruz, segment_method = &#39;day&#39;, segment_target_km = 30, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), density_types = c(&#39;S&#39;,&#39;F&#39;), density_modes = c(&#39;P&#39;,&#39;C&#39;), density_on_off = c(TRUE), distance_types = NULL, distance_modes = NULL, distance_on_off = NULL, random_seed = NULL) [1] &quot;separate&quot; [1] &quot;append&quot; &quot;segment&quot; [1] &quot;day&quot; [1] 833171 [1] 172800 [1] 30 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;separate&quot; [1] &quot;append&quot; &quot;segment&quot; [1] &quot;day&quot; [1] 833171 [1] 172800 [1] 30 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; &quot;N&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE # Number of segments cruz_demo$cohorts$default$density$segments %&gt;% nrow [1] 96 # Plot segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE) Contiguous vs. non-contiguous effort The example above allows for non-contiguous effort; a segment is allowed to contain effort separated by gaps as large as 24 hours (settings$max_interval). To coerce segments to represent only contiguous effort, make that setting very small: cruz_demo &lt;- segmentize(cruz, segment_method = &#39;equallength&#39;, segment_target_km = 30, segment_max_interval = .1, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), density_types = c(&#39;S&#39;,&#39;F&#39;), density_modes = c(&#39;P&#39;,&#39;C&#39;), density_on_off = c(TRUE), distance_types = NULL, distance_modes = NULL, distance_on_off = NULL, random_seed = NULL) [1] &quot;separate&quot; [1] &quot;append&quot; &quot;segment&quot; [1] &quot;equallength&quot; [1] 833171 [1] 360 [1] 30 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;separate&quot; [1] &quot;append&quot; &quot;segment&quot; [1] &quot;equallength&quot; [1] 833171 [1] 360 [1] 30 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; &quot;N&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE # Number of segments cruz_demo$cohorts$default$density$segments %&gt;% nrow [1] 493 # Plot segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE) You can see that many contiguous periods of effort were much shorter than the target length of 30 km. This is why allowing for non-contiguous effort can be advantageous for target segment lengths larger than 5 - 10 km. Segment remainder handling The default setting for segment_remainder_handling, c('append','segment'), means that remainders less than half the target length will be randomly appended to another segment, while remainders more than half will be treated as their own segment (and will be placed randomly along the trackline). If you don’t want that level of complexity, you can simply assign a single setting: c'append') will append the remainder in all cases, regardless of remainder length relative to the target length. The same idea goes for c('segment'). The other possible setting is disperse, which disperses the remainder evenly across all segments. To demonstrate, let’s use a target length of 100 km. cruz_demo &lt;- segmentize(cruz, segment_method = &#39;equallength&#39;, segment_target_km = 100, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;disperse&#39;), density_types = c(&#39;S&#39;,&#39;F&#39;), density_modes = c(&#39;P&#39;,&#39;C&#39;), density_on_off = c(TRUE), distance_types = NULL, distance_modes = NULL, distance_on_off = NULL, random_seed = NULL) [1] &quot;separate&quot; [1] &quot;disperse&quot; [1] &quot;equallength&quot; [1] 833171 [1] 172800 [1] 100 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;separate&quot; [1] &quot;disperse&quot; [1] &quot;equallength&quot; [1] 833171 [1] 172800 [1] 100 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; &quot;N&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE # Number of segments cruz_demo$cohorts$default$density$segments %&gt;% nrow [1] 80 # Plot segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE) Note that most segments are longer than the target length, due to the impact of dispersing the remainder. If you wanted, you could combat this by making the target length slightly smaller: cruz_demo &lt;- segmentize(cruz, segment_method = &#39;equallength&#39;, segment_target_km = 90, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;disperse&#39;), density_types = c(&#39;S&#39;,&#39;F&#39;), density_modes = c(&#39;P&#39;,&#39;C&#39;), density_on_off = c(TRUE), distance_types = NULL, distance_modes = NULL, distance_on_off = NULL, random_seed = NULL) [1] &quot;separate&quot; [1] &quot;disperse&quot; [1] &quot;equallength&quot; [1] 833171 [1] 172800 [1] 90 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;separate&quot; [1] &quot;disperse&quot; [1] &quot;equallength&quot; [1] 833171 [1] 172800 [1] 90 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; &quot;N&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE # Number of segments cruz_demo$cohorts$default$density$segments %&gt;% nrow [1] 89 # Plot segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE) But in general, the disperse option may be more appropriate for shorter segment lengths. Typical settings Design-based line transect analysis To replicate methods used in density estimation analyses, use large segment lengths (100 km or more) or simply segmentize by day, with S and F effort types kept separate. (See the examples above.) Remember that long segment lengths won’t work well unless you allow for non-contiguous effort. Habitat modeling To replicate the methods used in typical habitat modeling studies, use smaller segment lengths of contiguous effort. In these studies it may be acceptable to pool various effort types into the same segments. cruz_demo &lt;- segmentize(cruz, segment_method = &#39;equallength&#39;, segment_target_km = 5, segment_max_interval = .1, segment_type_handling = &#39;pool&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), density_types = c(&#39;S&#39;,&#39;F&#39;), density_modes = c(&#39;P&#39;,&#39;C&#39;), density_on_off = c(TRUE), distance_types = NULL, distance_modes = NULL, distance_on_off = NULL, random_seed = NULL) [1] &quot;pool&quot; [1] &quot;append&quot; &quot;segment&quot; [1] &quot;equallength&quot; [1] 833171 [1] 360 [1] 5 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;pool&quot; [1] &quot;append&quot; &quot;segment&quot; [1] &quot;equallength&quot; [1] 833171 [1] 360 [1] 5 [1] &quot;S&quot; &quot;F&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE [1] &quot;S&quot; &quot;F&quot; &quot;N&quot; [1] &quot;P&quot; &quot;C&quot; [1] TRUE # Number of segments cruz_demo$cohorts$default$density$segments %&gt;% nrow [1] 1729 # Plot segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE) "],["backlog.html", " 13 Appendix: Backlog", " 13 Appendix: Backlog Appendix for helper functions, incl species_translator(). Method for stratifying by Beaufort. Add setting to specify which species to pass on to Distance Handle probable species in process_sightings Add Survey summary function / section to this Rmd Add feature that calculates polygon area if not provided in stratum filename. study_area_explore() and study_area_select(). Figure out which ETP strata to have as defaults for both survey strata and study area polygons (there are like 100 in the folder Jeff sent us). May be a question for Tim G. Test this code on lots of cruise data files to establish basic functionality for Hawaii, California Current, and ETP. Build up settings file functionality for processing sightings (formatting DAT files for group size coefficients, etc.) Plotting functions for species (or subsets of species) Troubleshoot why longitudes are not displayed on Hawaii base map Accommodate subgroup settings for FKW analyses Close comparison to FORTRAN outputs Onward into next stages of Data Processing milestones "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
