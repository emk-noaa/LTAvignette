[["index.html", "vignette 1 Status", " vignette 1 Status This status report outlines the code we are developing to process WinCruz data and prepare it for density estimation analysis using distance and related packages in R. Recent changes New format_distance() function creates tables that match EFFORT.csv and SIGHTINGS.csv. (See here.) New process_surveys() function provides a wrapper for all data processing functions in a single command. This will be the main function that researchers use to process their data. All other functions are called within this function, and will rarely be called directly by researchers except in special analyses. This is explained at the top of the page on Data Processing. New helper function, read_polygon(), reads a DAT file of polygon coordinates and converts it to a dataframe compatible with LTabundR functions. Skeletonized new summary functions (see the Summarize page). Ship name is now added to all dataframes. New process_sightings() function, with code for calibrating group sizes according to user-provided coefficient tables (mirroring ABUND9 with slight mods, e.g., school size threshold for observers not in the Coeff.DAT file.). (Details: the function process_sightings() relies upon a utility function, group_size(), which in turn relies upon group_size_calibrate().) Added cohort-specific setting, school_size_calibrate, that allows researchers to specify whether a cohort should or should not have school sizes calibrated. Example use case: school_size_calibrate = TRUE for a cohort of dolphin species, but make it FALSE for a cohort of large baleen whales. Basic function for mapping sightings (QA/QC): map_sightings(). Added detail/polish to vignette pages on Settings, Processing Data, and the Appendix on Segmentizing. I believe these are ready for close review. Added detailed comments to code for all functions to date. Next focus Review INP files shared by Amanda EFFORT and SIGHTINGS outputs / stage for distance Survey summary Efficient system for testing on various datasets Document function manuals Questions for Amanda FKW handling What is the ship list used for? "],["install.html", " 2 Install LTabundR Option 1: Install from GitHub Option 2: Install locally", " 2 Install LTabundR Option 1: Install from GitHub Since the package is currently private, this is more complicated than it will be once the package is released. The first step is creating an R environment variable containing your GitHub personal access token. Complete these instructions only once: # Open your .Renviron file library(usethis) usethis::edit_r_environ() # Add your GitHub personal access token as a variable in `.Renviron` GITHUB_TOKEN = &#39;your_token_goes_here_as_a_character_string&#39; # Save and close your .Renviron file # Reload .Renviron readRenviron(&#39;~/.Renviron&#39;) Then run this code every time you want to reinstall / update the package: library(devtools) github_token &lt;- Sys.getenv(&quot;GITHUB_TOKEN&quot;) devtools::install_github(repo = &#39;amandalbradford/LTabundR-dev&#39;, subdir=&#39;LTabundR&#39;, auth_token=github_token, force=TRUE) library(LTabundR) Option 2: Install locally For now you can also install or update the package locally, using this code: library(devtools) # Remove the package, if you have an earlier version of it on your machine if(&#39;LTAabundR&#39; %in% installed.packages()){remove.packages(&#39;LTabundR&#39;)} # Specify the path to the package&#39;s project folder. path_to_package &lt;- &#39;../LTabundR&#39; # Update function documentation document(path_to_package) # Install package and any dependencies you need install(path_to_package) library(LTabundR) "],["settings.html", " 3 Settings Survey strata Study area polygon Survey-wide settings Cohort-specific settings Example code", " 3 Settings To customize the way data are processed and included in your analysis, use the load_settings() function. This function emulates and expands upon the settings file, ABUND.INP, that was used to run ABUND7/9 in FORTRAN. This function allows you to use ‘factory defaults’ if you don’t wish to specify anything special such as strata or study area polygons: settings &lt;- load_settings() If you do not want to use all the defaults, you can give load_settings() some custom inputs. The function accepts four arguments: strata: dataframe(s) of coordinates study_area: a dataframe of coordinates survey: settings that will apply universally to the analysis cohorts: settings that are specific to groups of species. By providing cohort-specific settings, the code for a single analysis becomes fully flexible to prepare and more easily reproduced, since the code only needs to be run once without modification. The output of load_settings() is a named list with a slot for each of these arguments: settings %&gt;% names [1] &quot;strata&quot; &quot;study_area&quot; &quot;survey&quot; &quot;cohorts&quot; Survey strata Stratum polygons can be provided as a named list of data.frame objects. Each data.frame must have Lat and Lon as the first two columns, providing coordinates in decimal degrees in which South and West coordinates are negative. Other columns are allowed, but the first two need to be Lon and Lat. The name of the slot holding the data.frame will be used as a reference name for the stratum. If strata is NULL, abundance will not be estimated; only density within the searched area (i.e., the total segment length x effective strip width). While users are welcome to upload polygons of their own, the package comes with “stock” polygons for strata that are commonly used in the main NMFS study regions: the Central North Pacific (CNP, including Hawaii) … data(strata_cnp) names(strata_cnp) [1] &quot;HI_EEZ&quot; &quot;WHICEAS&quot; &quot;OtherCNP&quot; …the California Current System (CCS) … data(strata_ccs) names(strata_ccs) [1] &quot;CCS&quot; &quot;Southern_CA&quot; &quot;Central_CA&quot; &quot;Nothern_CA&quot; &quot;OR_WA&quot; … and the Eastern Tropical Pacific (ETP): data(strata_etp) names(strata_etp) [1] &quot;MOPS_AreaCoreM&quot; &quot;MOPS_AreaIn&quot; &quot;MOPS_AreaIn1&quot; [4] &quot;MOPS_AreaIn2&quot; &quot;MOPS_AREAINS&quot; &quot;MOPS_AREAMID&quot; [7] &quot;MOPS_AreaMid1&quot; &quot;MOPS_AreaMid2&quot; &quot;MOPS_AreaMOPS&quot; [10] &quot;MOPS_AREANORS&quot; &quot;MOPS_AreaOuterM&quot; &quot;MOPS_AreaSou&quot; [13] &quot;MOPS_AREASOUS&quot; &quot;MOPS_AreaSpin&quot; &quot;MOPS_AreaSpinS&quot; [16] &quot;MOPS_AREAWES&quot; &quot;PODS_93STRAT1&quot; &quot;PODS_93STRAT2&quot; [19] &quot;PODS_Area92&quot; &quot;PODS_AREA92RS&quot; &quot;PODS_Area92s&quot; [22] &quot;PODS_AREA93&quot; &quot;PODS_AREA93A&quot; &quot;PODS_AREA93AR&quot; [25] &quot;PODS_AREA93AS&quot; &quot;PODS_AREA93BR&quot; &quot;PODS_AREA93M&quot; [28] &quot;PODS_AREA93MS&quot; &quot;PODS_AREA93R&quot; &quot;PODS_AREA93R1&quot; [31] &quot;PODS_AREA93R2&quot; &quot;PODS_AREA93RS&quot; &quot;PODS_AREA93S&quot; [34] &quot;PODS_AREANCOR&quot; &quot;PODS_GOCpoly&quot; &quot;Pre1986_Area79ES1&quot; [37] &quot;Pre1986_Area79ES1s&quot; &quot;Pre1986_Area79ES2&quot; &quot;Pre1986_Area79ES2s&quot; [40] &quot;Pre1986_Area79NE1&quot; &quot;Pre1986_Area79NE1s&quot; &quot;Pre1986_Area79NE2&quot; [43] &quot;Pre1986_Area79NE2s&quot; &quot;Pre1986_Area79NE3&quot; &quot;Pre1986_Area79NE3s&quot; [46] &quot;Pre1986_AreaCal&quot; &quot;Pre1986_AreaCals&quot; &quot;Pre1986_AreaMid&quot; [49] &quot;Pre1986_AreaMidS&quot; &quot;Pre1986_AreaNorth&quot; &quot;Pre1986_AreaNorthS&quot; [52] &quot;Pre1986_AreaSouth&quot; &quot;Pre1986_AreaSouthS&quot; &quot;STAR_Area98a&quot; [55] &quot;STAR_Area98b&quot; &quot;STAR_AreaCore&quot; &quot;STAR_AreaCore2&quot; [58] &quot;STAR_AreaCoreS&quot; &quot;STAR_AreaNCoast&quot; &quot;STAR_AreaNCstS&quot; [61] &quot;STAR_AreaOuter&quot; &quot;STAR_AreaOuter00&quot; &quot;STAR_AreaSCoast&quot; [64] &quot;STAR_AreaSCstS&quot; &quot;STAR_AreaSPn&quot; &quot;STAR_AreaSPs&quot; [67] &quot;STAR_AreaSTAR&quot; &quot;STAR_AreaSTAR2&quot; &quot;STAR_AreaSTARlite&quot; [70] &quot;STAR_Dcaparea&quot; The package includes functions for visualizing and selecting from these strata. See the Strata Gallery appendix. Study area polygon The study_area argument accepts a single data.frame, formatted the same as those for the strata argument, or a numeric value indicating the area of your study area in square km. If study_area is NULL, abundance will not be estimated; only density. Study area polygons can be provided in the same format as strata: a two-column csv (column names Lon and Lat with decimal-degree coordinates). A stock study area polygon is available for the CNP: data(study_cnp) study_cnp Lon Lat 1 -131 40.00 2 -126 32.05 3 -120 25.00 4 -120 -5.00 5 -185 -5.00 6 -185 40.00 7 -131 40.00 Survey-wide settings Survey-wide settings apply universally to all species in the analysis. Defaults settings$survey $segment_method [1] &quot;day&quot; $segment_target_km [1] 150 $segment_max_km_gap [1] 5 $segment_max_interval [1] 48 $segment_type_handling [1] &quot;separate&quot; &quot;pool&quot; $segment_remainder_handling [1] &quot;append&quot; &quot;segment&quot; $ship_list NULL $species_codes NULL $group_size_coefficients NULL $smear_angles [1] FALSE $random_seed [1] 833171 $verbose [1] TRUE Defaults for the survey argument list are built up efficiently using the function load_survey_settings() (see example code at bottom). Details The survey_settings input accepts a list with any of the following named slots. The first few slots are devoted to controlling how effort will be “segmentized”, or chopped into discrete sections for the purposes of estimating the variabce of the abundance estimate. segment_method: the two method options are \"day\" – all effort within the same Cruise-StudyArea-Stratum-Year-Effort scenario will be binned into segments by calendar date – and \"equallength\" – effort within each unique effort scenario (Cruise-StudyArea-etc.) will be divided into segments of approximately equal length. See the Appendix on segmentizing for details. segment_target_km: if segmenting by \"equallength\", this field allows you to specify what that target length is, in km. segment_max_km_gap: the segmentizing function works by calculating the distance between each row of DAS data. If that distance exceeds the length specified here (e.g., 5 km), the function will assume that there was a break in effort. segment_max_interval: if segmentizing by \"equallength\", this setting allows you to specify the time gaps in effort that are allowed to be contained within a single segment. For example, if your goal is a few large segments of equal length (e.g., 150-km segments, for bootstrap estimation of density variance), you are probably willing for discrete periods of effort to be concatenated into a single segment, even if the gaps between effort are as large as 1 or 2 days, in which case you would set segment_max_interval to 24 or 48 (hours), respectively. However, if your goal is many smaller segments (e.g., 5-km segments, for habitat modeling), you want to ensure that effort is contiguous so that segment locations can be accurately related to environmental variables, in which case you would set segment_max_interval to be very small (e.g., .2 hours, or 12 minutes). Setting this interval to a small number, such as 0.2, also allows the segmentizing function overlook momentary breaks in effort, such as when an unofficial observer logs a sighting. segment_type_handling: if \"pool\", all effort types that qualify as valid according to cohort_settings (see next section) will be pooled together, making it possible for different effort types to occur in the same segment. Specifically, when this setting is \"pool\", the EffType’s “S” and “F” are allowed to occur in the same segment; if this argument is \"separate\", segments will only be allowed to contain a single effort type. segment_remainder_handling: if segmentizing by \"equallength\", periods of effectively-contiguous effort (as specified by segment_max_interval) are unlikely to be perfectly divisible by your segment_target_km; there is going to be a remainder. You can handle this remainder in three ways: (1) \"disperse\" allows the function to adjust segment_target_km so that there is in fact no remainder, effectively dispersing the remainder evenly across all segments within that period of contiguous effort; (2) \"append\" asks the function to append the remainder to a randomly selected segment, such that most segments are the target length with the exception of one longer one; or (3) \"segment\" asks the function to simply place the remainder in its own segment, placed randomly within the period of contiguous effort. This setting also has a second layer of versatility, because it can accept a one- or two-element character vector. If a two-element vector is provided (e.g., c(\"append\",\"segment\")), the first element will be used in the event that the remainder is less than or equal to half your segment_target_km; if the remainder is more than half that target length, the second element will be used. This feature allows for replication of the segmentizing methods in Becker et al. (2010). The remaining slots in survey_settings pertain to various datasets and settings used in data processing: ship_list: A data.frame containing a list of ship names. If not provided the default version, which was current as of the release of ABUND9 in 2020, will be used (data(ships)). Supplied data.frames must match the column naming structure of data(ships). species_codes: A data.frame containing species codes. If not provided the default version, which was current as of the release of ABUND9 in 2020, will be used (data(species_codes)). Supplied data.frames must match the column naming structure of data(species_codes). group_size_coefficients: A data.frame of calibration factors. Find details in the subsection on processing sightings and estimating school size. smear_angles: If TRUE (the default is FALSE), bearing angles to a group of animals will be “smeared” by adding a uniformly distributed random number between -5 and +5 degrees. This has not been used in any recent analyses because observers have not been rounding angles as much as they used to. It was suggested by Buckland as a method for dealing with rounding which is especially influential when rounding to zero places many sightings at zero perpendicular distance. random_seed: a number used as the seed for stages involving random number generation. If not NULL, the results will be exactly reproducible. Default is 833171 (sensu example code in ABUND9). verbose: If TRUE (the default), status updates will be printed to the R console. Cohort-specific settings Cohort-specific settings apply only to a group of species. Since you can add as many cohorts to a settings object as you need, this allows you to stage your entire analysis and run your code once, without modifying code between the analysis of each cohort. Defaults The default is to use a single cohort for all species: settings$cohorts %&gt;% names [1] &quot;default&quot; Default values for the default cohort: settings$cohorts$default $id [1] &quot;default&quot; $species NULL $probable_species [1] FALSE $sighting_method [1] 0 $cue_range [1] 0 1 2 3 4 5 6 7 $school_size_range [1] 0 10000 $school_size_calibrate [1] TRUE $use_low_if_na [1] FALSE $io_sightings [1] 0 $geometric_mean_group [1] TRUE $truncation_km [1] 5.5 $beaufort_range [1] 0 1 2 3 4 5 6 $abeam_sightings [1] FALSE $strata_overlap_handling [1] &quot;smallest&quot; &quot;largest&quot; &quot;each&quot; $density_types [1] &quot;S&quot; &quot;F&quot; $density_modes [1] &quot;P&quot; &quot;C&quot; $density_on_off [1] TRUE $distance_types NULL $distance_modes NULL $distance_on_off [1] TRUE Defaults for the cohorts argument list is built up efficiently using the function load_cohort_settings() (see example code at bottom). Details The cohort_settings input accepts a list of any length. Each slot in that list can contain settings for a different cohort. Each cohort list can have any of the following named slots: id: An informal identifier for this cohort, to help you keep track of which cohort is which. For example, settings for a cohort of large whales species could be named \"big whales\"; settings for small delphinids and phocoenids could be named \"small_odontocetes\"; settings for beaked whales could be named \"beakers\". species: A vector of species codes to include in this cohort. If NULL (the default), all species will be included. probable_species: If TRUE (default is FALSE), the “probable” species identifications will be used in place of the “unidentified” categories. sighting_method: A coded integer which determines which sightings will be included based on how they were first seen. Allowable codes are 0=any method, 1=with 25X only, 2=neither with 25x binoculars nor from the helicopter (i.e., naked eyes and 7x binoculars only). These codes match those used in ABUND7/9. cue_range: Numeric vector of acceptable “observation cues” for sightings used in estimates of abundance. (0=this detail is missing in the data, 1=associated birds, 2=splashes, 3=body of the marine mammal, 4=associated vessel, 5=?, 6=blow / spout, 7=associated helicopter). These codes match those used in ABUND7/9. school_size_range: Minimum and maximum group sizes to be included in estimates of abundance. This is the overall group size, not the number of the given species that are present in a group. school_size_calibrate: A logical (TRUE or FALSE) specifying whether or not to carry out school size adjustments according to the calibration table provided in survey$group_size_coefficients (if that table is provided). This setting allows you to toggle the survey-wide setting for certain cohorts. For example, perhaps you want to carry out calibration for a cohort of dolphin species, but not for a cohort of large whales whose group sizes tend to be smaller and easier to estimate accurately. use_low_if_na: If this setting is TRUE, an observer does not make a best estimate of group size, mean group size will be calculated from “low” estimates. This will be done only if no observer has a “best” estimate. io_sightings: A coded integer which specifies how sightings by the independent observer will be handled. Allowable codes, which are inherited from those used in ABUND7/9, are \"_1\"=include independent observer sightings wih all other sightings, \"0\"=ignore sightings by independent observer, \"1\"=use only sightings made by regular observer team WHEN an independent observer was present, \"2\"=include only sightings made by the independent observer. IO sightings are typically used only for making g(0) estimates, otherwise IO sightings are usually ignored (code = \"0\"). geometric_mean_group: This logical variable specifies whether to use a weighted geometric mean when calculating mean group size. Barlow, Gerrodette, and Perryman (1998) found that this gave slightly better performance than a straight mean group size. Default is TRUE, but it will only be done if group_size_coefficients is not NULL. truncation_km: Specifies the maximum perpendicular distance for groups that are to be included for abundance estimation. Also determines the bins used for grouped perpendicular distances. beaufort_range: Vector of Beaufort sea states (integers) that are acceptable in estimating the detection function and density. Beaufort data with a decimal place will be rounded to the nearest integer to evaluate for inclusion. abeam_sightings: = If TRUE, sightings that occur aft of beam are included in estimating the detectin function and densities. Default is FALSE: all abeam sightings will be ignored. strata_overlap_handling: In the event that survey strata overlap, this setting tells R how to handle it. The options are \"smallest\" (the default), in which effort can belong to only a single stratum, and the smallest of overlapping strata will be used (e.g., an insular polygon nested within a larger EEZ polygon); \"largest\", in which effort can belong to only a single stratum and the largest of overlapping strata will be used (we are not sure what use case this would serve, but we offer it as an option for niche analyses); and \"each\", in which each effort is allowed to belong to two or more strata at once and all analyses will be conducted for each overlapping polygon separately (e.g., this may be appropriate for nested strata in which you want to estimate density in the entirety of the larger stratum in addition to estimating density for the nested stratum). density_types: A character vector of the effort types that will be included in detection function estimation and density estimation, and therefore considered in effort segmentizing. Accepted values are \"S\" (systematic/standard effort), \"F\" (fine-scale effort), and \"N\" (non-systematic/non-standard effort, in which systematic protocols are being used but effort is not occurring along design-based transect routes). The default values are c(\"S\",\"F\"). density_modes: The effort modes that will be included in detection function estimation and density estimation, and therefore considered in effort segmentizing. Accepted values are \"P\" (passing) and \"C\" (closing), and the default values are c(\"P\",\"C\"). density_on_off: The value(s) of OnEffort (On Effort is TRUE, Off Effort is FALSE) that will be included in detection function estimation and density estimation, and therefore considered in effort segmentizing. Default is TRUE only. (We don’t expect FALSE or c(TRUE,FALSE) to be used much, if at all, but we make this option available). distance_types: If effort types are specified in this argument, this selection will be used to filter data for estimation of the detection function. If left NULL (the default), the argument density_types will be used. This option will be rarely used, but it may prove helpful in cases in which sightings for a species are so few that including all effort types (c('S','F','N')) may be justifiable for estimating the detection function, even if only 'S' and 'F' are used for density estimation. distance_modes: Same idea as distance_types above, but for effort modes (Passing / Closing). distance_on_off: Same idea as distance_types above, but for OnEffort status (TRUE or FALSE). Example code Use settings defaults (no strata) settings &lt;- load_settings() Use settings defaults with strata # Load strata dataframes data(strata_cnp) data(study_cnp) settings &lt;- load_settings(strata = strata_cnp, study_area = study_cnp) Customize survey, but not cohorts When a cohort is not specified, the default values will be used. # Load strata dataframes data(strata_cnp) data(study_cnp) # Survey settings survey &lt;- load_survey_settings(segment_method = &#39;equallength&#39;, segment_target_km = 30, segment_max_km_gap = 5, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), verbose = TRUE) # Load settings settings &lt;- load_settings(strata = strata_cnp, study_area = study_cnp, survey) Fully custom: strata, study area, survey &amp; cohorts These are the settings we will use in the remainder of the tutorial: # Load strata data(strata_cnp) data(study_cnp) # Survey settings survey &lt;- load_survey_settings(segment_method = &#39;equallength&#39;, segment_target_km = 30, segment_max_km_gap = 5, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), verbose = TRUE) # Cohort 1 (default) cohort1 &lt;- load_cohort_settings() # Cohort 2 cohort2 &lt;- load_cohort_settings(id=&#39;fkw_insular&#39;, species=33, use_low_if_na = TRUE, truncation_km = 5, strata_overlap_handling = &#39;each&#39;) # Load settings settings &lt;- load_settings(strata = strata_cnp, study_area = study_cnp, survey = survey, cohorts=list(cohort1, cohort2)) "],["processing.html", " 4 Data processing Bring in cruise data Format DAS data Process strata Segmentize the data Process sightings Review", " 4 Data processing You can process your survey data using a single function, process_surveys(), which takes two arguments: the filepath(s) to your DAS survey data, and your settings object. For example: process_surveys(das_file = &#39;data/surveys/HICEASwinter2020.das&#39;, settings = settings) That single command will convert your raw DAS data to a “cruz” object, a list of polished datasets that are prepared to be passed to subsequent analyses. That function is a wrapper for several discrete stages of data formatting/processing. Behind the scenes, each of those stages is carried out using a specific LTabundR function. The remainder of this page is a detailed step-by-step explanation of the data processing that occurs when you call process_surveys(). Bring in cruise data Specify the path to your .DAS data file(s): das_file &lt;- &#39;data/surveys/HICEASwinter2020.das&#39; Read in and process this .DAS file using the functions in Sam’s swfscDAS package. To do so quickly, we built a wrapper function that makes this quick and easy: das &lt;- load_das(das_file, perform_checks = TRUE, print_glimpse = TRUE) Cruise numbers: 2001 &lt;NA&gt; 48 0 Rows: 22,486 Columns: 40 $ Event &lt;chr&gt; &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;*&quot;, &quot;B&quot;, &quot;R&quot;, … $ DateTime &lt;dttm&gt; 2020-01-19 07:11:52, 2020-01-19 07:13:52, 2020-01-19 07:15:… $ Lat &lt;dbl&gt; 21.79983, 21.80517, 21.81050, 21.81583, 21.82133, 21.82667, … $ Lon &lt;dbl&gt; -159.7652, -159.7657, -159.7662, -159.7668, -159.7673, -159.… $ OnEffort &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS… $ Cruise &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2001, 2001, 2001, 20… $ Mode &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, … $ OffsetGMT &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, -10, -10, -10, -10, … $ EffType &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;… $ ESWsides &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, 2, 2, 2, 2, 2… $ Course &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 350,… $ SpdKt &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 9.9,… $ Bft &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4, 4, 4,… $ SwellHght &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 6, 6, 6,… $ WindSpdKt &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 15, 15, … $ RainFog &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ HorizSun &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ VertSun &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Glare &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Vis &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ ObsL &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;126&quot;, &quot;126&quot;… $ Rec &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;307&quot;, &quot;307&quot;… $ ObsR &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;238&quot;, &quot;238&quot;… $ ObsInd &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data1 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;2001&quot;, &quot;F&quot;, &quot;126&quot;, … $ Data2 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;C&quot;, NA, &quot;307&quot;, &quot;06&quot;… $ Data3 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;-10&quot;, NA, &quot;238&quot;, &quot;1… $ Data4 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;N&quot;, NA, NA, NA, NA,… $ Data5 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;15.0&quot;, … $ Data6 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data7 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data8 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data9 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data10 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data11 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ Data12 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … $ EffortDot &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS… $ EventNum &lt;chr&gt; &quot;001&quot;, &quot;002&quot;, &quot;003&quot;, &quot;004&quot;, &quot;005&quot;, &quot;006&quot;, &quot;007&quot;, &quot;008&quot;, &quot;009… $ file_das &lt;chr&gt; &quot;HICEASwinter2020.das&quot;, &quot;HICEASwinter2020.das&quot;, &quot;HICEASwinte… $ line_num &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1… Format DAS data Finalize formatting: remove rows with invalid locations and calculate the distance, in km, between each row of data. Other refinements can be added to this function later on. das &lt;- format_das(das, settings) par(mfrow=c(1,2)) hist(das$km_int, xlab=&#39;KM between each DAS row&#39;, main=NULL, breaks=seq(0,max(das$km_int),length=100)) plot(das$km_cum, ylab=&#39;Cumulative KM surveyed&#39;, main=NULL, type=&#39;l&#39;) Process strata Run the following function to add strata and study-area information to each sub-segment of effort: cruz &lt;- process_strata(das, settings) Spherical geometry (s2) switched off This function loops through each stratum data.frame you have provided it in settings$strata, formats the stratum, and asks whether each DAS row occurs within it. For each stratum, a column named stratum_&lt;StratumName&gt; is added to the das object; each row in this column is TRUE (included) or FALSE. A similar procedure is run if a dataframe is provided in settings$study_area. A column named study_area is added to das containing a boolean (TRUE if the sub-segment or sighting occurs within the study area). The function then loops through each species cohort and uses that cohort’s settings to determine a single stratum assignment for each row of DAS data in the event of overlapping strata. The key cohort setting referenced here is stratum_overlap_handling. The cruz object The function process_strata() returns a list, which we have saved in an object named cruz, with several slots: cruz %&gt;% names [1] &quot;das&quot; &quot;settings&quot; &quot;strata&quot; &quot;study_area&quot; &quot;cohorts&quot; The slots strata and study_area provide the area, in square km, of each polygon being used: cruz$strata stratum area 1 HI_EEZ 2491447.3 2 WHICEAS 419789.2 3 OtherCNP 34232739.5 cruz$study_area [1] 34232739 The slot cohorts is itself a list with one slot for each cohort. The slots are named using the id cohort setting. cruz$cohorts %&gt;% names [1] &quot;default&quot; &quot;fkw_insular&quot; Each cohort slot has a copy of the DAS data with a stratum assignment tailored to its cohort-specific settings. For instance, the default cohort, whose stratum_overlap_handling is set to \"smallest\", assigns the smallest stratum in the event of overlapping or nested strata: cruz$cohorts$default$stratum %&gt;% table(useNA=&#39;ifany&#39;) . HI_EEZ WHICEAS 142 22228 The fkw_insular cohort, whose stratum_overlap_handling is set to \"each\" (i.e., effort is allowed to belong to multiple segments, if they overlap, and all analyses will be conducted for each stratum separately), has stratum assignments that look like this; cruz$cohorts$fkw_insular$stratum %&gt;% table(useNA=&#39;ifany&#39;) . HI_EEZ&amp;OtherCNP HI_EEZ&amp;WHICEAS&amp;OtherCNP 142 22228 When a row of DAS effort occurs in two overlapping strata, the stratum assignment for that row is a concatentation of the names of the strata it falls within, with names separated by “&amp;”. This list, with these five primary slots, will be referred to as a cruz object. The remainder of the data processing work flow is focused upon refining the effort and sighting data for each slot in cohorts. The other slots are no longer modified. Segmentize the data To allocate survey data into discrete ‘effort segments’, which are used in variance estimation in subsequent steps, run the function segmentize(). This process is controlled by both survey-wide and cohort-specific settings, which are now carried in a slot within the cruz object. The process is outlined in detail in the Appendix on Segmentizing. cruz &lt;- segmentize(cruz, verbose=TRUE) Error: Must group by variables found in `.data`. * Column `study_area` is not found. This function does not change the high-level structure of the cruz object … cruz %&gt;% names [1] &quot;das&quot; &quot;settings&quot; &quot;strata&quot; &quot;study_area&quot; &quot;cohorts&quot; … or the cohort names in the cohorts slot … cruz$cohorts %&gt;% names [1] &quot;default&quot; &quot;fkw_insular&quot; But it does change the structure of data within each cohort. Each cohort will now have a slot named density … cruz$cohorts$default %&gt;% names [1] &quot;Event&quot; &quot;DateTime&quot; &quot;Lat&quot; &quot;Lon&quot; [5] &quot;OnEffort&quot; &quot;Cruise&quot; &quot;Mode&quot; &quot;OffsetGMT&quot; [9] &quot;EffType&quot; &quot;ESWsides&quot; &quot;Course&quot; &quot;SpdKt&quot; [13] &quot;Bft&quot; &quot;SwellHght&quot; &quot;WindSpdKt&quot; &quot;RainFog&quot; [17] &quot;HorizSun&quot; &quot;VertSun&quot; &quot;Glare&quot; &quot;Vis&quot; [21] &quot;ObsL&quot; &quot;Rec&quot; &quot;ObsR&quot; &quot;ObsInd&quot; [25] &quot;Data1&quot; &quot;Data2&quot; &quot;Data3&quot; &quot;Data4&quot; [29] &quot;Data5&quot; &quot;Data6&quot; &quot;Data7&quot; &quot;Data8&quot; [33] &quot;Data9&quot; &quot;Data10&quot; &quot;Data11&quot; &quot;Data12&quot; [37] &quot;EffortDot&quot; &quot;EventNum&quot; &quot;file_das&quot; &quot;line_num&quot; [41] &quot;year&quot; &quot;month&quot; &quot;day&quot; &quot;yday&quot; [45] &quot;km_int&quot; &quot;km_cum&quot; &quot;ship&quot; &quot;stratum_HI_EEZ&quot; [49] &quot;stratum_WHICEAS&quot; &quot;stratum_OtherCNP&quot; &quot;study_area.x&quot; &quot;study_area.y&quot; [53] &quot;stratum&quot; And, if your settings specify that settings for density estimation differ from detection function estimation, a cohort will have a second slot named distance. This is the case for the second cohort in our example analysis: fkw_insular. cruz$cohorts$fkw_insular %&gt;% names [1] &quot;Event&quot; &quot;DateTime&quot; &quot;Lat&quot; &quot;Lon&quot; [5] &quot;OnEffort&quot; &quot;Cruise&quot; &quot;Mode&quot; &quot;OffsetGMT&quot; [9] &quot;EffType&quot; &quot;ESWsides&quot; &quot;Course&quot; &quot;SpdKt&quot; [13] &quot;Bft&quot; &quot;SwellHght&quot; &quot;WindSpdKt&quot; &quot;RainFog&quot; [17] &quot;HorizSun&quot; &quot;VertSun&quot; &quot;Glare&quot; &quot;Vis&quot; [21] &quot;ObsL&quot; &quot;Rec&quot; &quot;ObsR&quot; &quot;ObsInd&quot; [25] &quot;Data1&quot; &quot;Data2&quot; &quot;Data3&quot; &quot;Data4&quot; [29] &quot;Data5&quot; &quot;Data6&quot; &quot;Data7&quot; &quot;Data8&quot; [33] &quot;Data9&quot; &quot;Data10&quot; &quot;Data11&quot; &quot;Data12&quot; [37] &quot;EffortDot&quot; &quot;EventNum&quot; &quot;file_das&quot; &quot;line_num&quot; [41] &quot;year&quot; &quot;month&quot; &quot;day&quot; &quot;yday&quot; [45] &quot;km_int&quot; &quot;km_cum&quot; &quot;ship&quot; &quot;stratum_HI_EEZ&quot; [49] &quot;stratum_WHICEAS&quot; &quot;stratum_OtherCNP&quot; &quot;study_area.x&quot; &quot;study_area.y&quot; [53] &quot;stratum&quot; Though their data segmentization will differ, the density and distance slots have identical structures: cruz$cohorts$fkw_insular$density %&gt;% names NULL cruz$cohorts$fkw_insular$distance %&gt;% names NULL The segments slot contains summary data for each effort segment, including start/mid/end coordinates, average conditions, and segment distance: cruz$cohorts$default$density$segments %&gt;% glimpse NULL # Number of segments cruz$cohorts$default$density$segments %&gt;% nrow NULL # Segment length distribution hist(cruz$cohorts$default$density$segments$dist, breaks = seq(0,60,by=1), xlab=&#39;Segment lengths (km)&#39;, main=paste0(&#39;Target km: &#39;,settings$survey$segment_target_km)) Error in hist.default(cruz$cohorts$default$density$segments$dist, breaks = seq(0, : &#39;x&#39; must be numeric The effort slot is itself a list in which each slot holds the DAS for a single segment. cruz$cohorts$default$density$effort %&gt;% length [1] 0 And the das slot holds the original data.frame of DAS data, modified slightly: the column OnEffort has been modified according to Beaufort range conditions, and the column seg_id indicates which segment the event occurs within cruz$cohorts$default$density$das %&gt;% names NULL The segmentize() function and its associated settings were designed to give researchers full control over how data are segmented, be it for design-based density analysis (which tend to use long segments of 100 km or more and allow for non-contiguous effort to be included in the same segment) or for habitat modeling (which tend to use short segments of 5 - 10 km and disallow non-contiguous effort to be pooled into the same segment). To demonstrate that versatility, checkout the appendix on segmentizing. Process sightings To process sightings for each cohort of species, use the function process_sightings(). This function has three basic steps: for each cohort, the function (1) prepares a sightings table using the function das_sight() from swfscDAS; (2) filters those sightings to species codes specified for the cohort in your settings input; and (3) evaluates each of those sightings, asking if each should be included in the analysis according to your settings. cruz &lt;- process_sightings(cruz) Error: $ operator is invalid for atomic vectors The function produces a formatted dataset and adds it to a new sightings slot. It does this for each analysis (density and, if specified, distance) in each cohort. cruz$cohorts$default$density %&gt;% names NULL cruz$cohorts$fkw_insular$density %&gt;% names NULL cruz$cohorts$fkw_insular$distance %&gt;% names NULL Note that the sightings table has a column named included (TRUE = yes, use it in the analysis). Any sightings that do not meet the inclusion criteria as specified in your settings will be included = FALSE, but they won’t be removed from the data. Since the sightings in each cohort are processed slightly differently according to the cohort’s specific settings, you should expect different numbers of included/excluded sightings in each cohort-analysis dataset: cruz$cohorts$default$density$sightings$included %&gt;% table &lt; table of extent 0 &gt; cruz$cohorts$fkw_insular$density$sightings$included %&gt;% table &lt; table of extent 0 &gt; cruz$cohorts$fkw_insular$distance$sightings$included %&gt;% table &lt; table of extent 0 &gt; When this function’s verbose argument is TRUE (the default), a message is printed each time a sighting does not meet the inclusion criteria (see above). Sightings data structure The sightings table has many other variables: cruz$cohorts$default$density$sightings %&gt;% names NULL Columns 41 onwards correspond to sightings information. Columns of note: species (column 68) contains the species code. There is only one species-code per row (i.e, multi-species sightings have been expanded to multiple rows). best, low, and high (columns 69- 71) contain the refined group size estimates, averaged across observers and calibrated according to the cohort’s settings specifications. For multi-species sightings, these numbers represent the number of individuals for the single species represented in the row (i.e., the original group size estimate has been scaled by the percentage attritbuted to this species). The columns following those group size estimates (prob through calibr) detail how group sizes were estimated: prob indicates whether probable species codes were accepted; mixed indicates whether this species’ sighting is part of a mixed-species sighting; n_sp provides the number of species occurring in this sighitng; n_obs gives the number of observers who contributed group size estimates; n_best through n_high gives the number of valid group size estimates given; and calibr indicates whether or not calibration was attempted for this sighting based on the settings (see next section). As explained above, the final column, included, indicates whether this species should be included in the analysis. Here is a glimpse of the data: cruz$cohorts$fkw_insular$distance$sightings %&gt;% glimpse NULL Note that the process_sightings() function draws upon cruz$settings for inclusion criteria, but some of those settings can be overridden with the function’s manual inputs if you want to explore your options (see below). School size estimates In the settings we are using in this tutorial, school size estimates are adjusted using the calibration models from Barlow, Gerrodette, and Perryman (1998) (their analysis is refined slightly and further explained in Gerrodette, Perryman and Barlow, 2002). These calibration corrections are observer-specific. Some observers tend to underestimate school size and their estimates are adjusted up; others tend to overestimate and their estimates are adjusted down. Some observers do not have calibration coefficients, and for them a generic adjustment (upwards, by dividing estimates by 0.8625) is used. Each observer’s estimate is calibrated, then all observer estimates are averaged. To do that averaging, our settings specify that we shall use a geometric weighted mean, instead of an arithmetic mean, that weights school size estimates from multiple observers according to the variance of their calibration coefficients. Here are our current best estimates of school size: cruz$cohorts$default$density$sightings$best %&gt;% head(20) NULL Let’s compare those estimates to unadjusted ones, in which calibration (and therefore weighted geometric mean) is turned off: cruz_demo &lt;- process_sightings(cruz, calibrate = FALSE, verbose = FALSE) Error: $ operator is invalid for atomic vectors cruz_demo$cohorts$default$density$sightings$best %&gt;% head(20) Error in head(., 20): object &#39;cruz_demo&#39; not found Note that, since calibration is only used for schools above a certain size, the difference between calibration and non-calibrated estimates becomes clearer in larger groups. You can also carry out calibration corrections without using a geometric weighted mean (the arithmetic mean will be used instead): cruz_demo &lt;- process_sightings(cruz, calibrate = TRUE, geometric_mean = FALSE, verbose = FALSE) Error: $ operator is invalid for atomic vectors cruz_demo$cohorts$default$density$sightings$best %&gt;% head(20) Error in head(., 20): object &#39;cruz_demo&#39; not found Note that school size calibration is only carried out if settings$group_size_calibration is not NULL. However, even when calibration coefficients are provided, calibration is only carried out for raw estimates above a minimum threshold, since observers are unlikely to mis-estimate the school size of a lone whale or pair. For observers who have calibration coefficients in the settings$group_size_coefficients table, that minimum is specified for each observer individually. For observers not in that table, calibration will only be applied to raw school size estimates of 4 or above. Review By the end of this process, you have a single data object, cruz, with all the data you need to move forward into the next stages of mapping and analysis. cruz %&gt;% names [1] &quot;das&quot; &quot;settings&quot; &quot;strata&quot; &quot;study_area&quot; &quot;cohorts&quot; Each species-specific cohort has its own list under cruz$cohorts: cruz$cohorts %&gt;% names [1] &quot;default&quot; &quot;fkw_insular&quot; Each of these cohorts can have two lists, density and distance, which contain the data to be used in those density estimation and detection function estimation, respectively: str(cruz$cohorts, max.level=2, list.len = 10, vec.len = 0, give.length = FALSE, give.attr = FALSE) List of 2 $ default :&#39;data.frame&#39;: 22370 obs. of 53 variables: ..$ Event : chr ... ..$ DateTime : POSIXct, format: ... ..$ Lat : num NULL ... ..$ Lon : num NULL ... ..$ OnEffort : logi NULL ... ..$ Cruise : num NULL ... ..$ Mode : chr ... ..$ OffsetGMT : int NULL ... ..$ EffType : chr ... ..$ ESWsides : num NULL ... .. [list output truncated] $ fkw_insular:&#39;data.frame&#39;: 22370 obs. of 53 variables: ..$ Event : chr ... ..$ DateTime : POSIXct, format: ... ..$ Lat : num NULL ... ..$ Lon : num NULL ... ..$ OnEffort : logi NULL ... ..$ Cruise : num NULL ... ..$ Mode : chr ... ..$ OffsetGMT : int NULL ... ..$ EffType : chr ... ..$ ESWsides : num NULL ... .. [list output truncated] Each of these analysis slots is a list with the same elements: cruz$cohorts$default$density %&gt;% names NULL segments is a summary table of segments. effort is a list in which each slot contains DAS data for a single segment. das is the raw DAS data, modified with seg_id to associate each row with a segment. sightings is a dataframe of sightings processed according to this cohort’s settings. In each dataframes for each cohort-analysis (e.g., default$density), there are three critically important columns to keep in mind: seg_id: this column is used to indicate the segment ID a row of data belongs to. use: this column indicates whether a row of effort should be used in the analysis. Every row of data within a single segment with have the same use value. included: this column occurs in the sightings dataframe only. It indicates whether the sightings should be included in the analysis based on the specified settings. Any sighting with use == FALSE will also have included == FALSE, but it is possible for sightings to have use == TRUE with included == FALSE. For example, if the setting abeam_sightings is set to FALSE, a sighting with a bearing angle beyond the ship’s beam can be excluded from the analysis (included == FALSE) even though the effort segment it occurs within will still be used (use == TRUE). "],["maps.html", " 5 Maps Base maps Add strata Add survey tracks Add sightings", " 5 Maps To build a flexible system for mapping cruise data, we have the following functions: Base maps Begin with a basic map, including EEZ borders: m &lt;- map_base(region=&#39;cnp&#39;) m We also have a base map for the California Current … m &lt;- map_base(region=&#39;ccs&#39;) m And the ETP: m &lt;- map_base(region=&#39;etp&#39;) m Add strata Add your research strata to your map: m &lt;- map_base(region=&#39;cnp&#39;) m &lt;- map_strata(m, cruz$settings, region=&#39;cnp&#39;) m Add survey tracks m1 &lt;- map_effort(m, cruz) m1 The defaults of map_effort() assume, for simplicity, that you want to see the segments to be included in density estimation for the first cohort specified in your settings. You can adjust this and other defaults using the function arguments. Customizing effort Inputs To demonstrate some of the customization options, consider this map that shows segments to be excluded from the \"distance\" (detection function) analysis for our second cohort (fkw_insular). map_effort(m, cruz, cohort = 2, analysis = &#39;distance&#39;, use_type = c(FALSE), effort_color=&#39;firebrick&#39;, effort_stroke=2.5, effort_linetype=1,) Color-code conditions Your second customization option is to add format variables to the segments slot of the cohort of interest in the cruz object. This gives you full control of line color, thickness, and line-type according to whatever specifications you wish to set, e.g., color-coding by effort type or Beaufort sea state. This is possible because the function map_effort() looks for the variables col (line color), lwd (line thickness or stroke), and lty (line type) in the columns of cruz$segments. If these columns exist, the values therein will be used instead of the function defaults. For example, color-code by Beaufort scale: # Save copy of cruz object data to modify cruz2 &lt;- cruz segments &lt;- cruz2$cohorts$default$density$segments # Add column `col`: color code by BFT sea state bft_colors &lt;- c(&#39;steelblue4&#39;,&#39;steelblue2&#39;,&#39;cadetblue1&#39;,&#39;grey&#39;) segments$col &lt;- bft_colors[4] segments$col[ segments$avgBft &lt;= 7 ] &lt;- bft_colors[3] # bft 5 + segments$col[ segments$avgBft &lt;= 4 ] &lt;- bft_colors[2] # bft 3 - 4 segments$col[ segments$avgBft &lt;= 2 ] &lt;- bft_colors[1] # bft 0 -2 # Update sub_segments slot in `cruz` object cruz2$cohorts$default$density$segments &lt;- segments # Update map m_custom2 &lt;- map_effort(m, cruz2) # Add legend using native functions from mapping package `tmap` m_custom2 &lt;- m_custom2 + tmap::tm_add_legend(&#39;line&#39;, col = bft_colors, lwd = 3, labels = c(&#39; 0 - 2&#39;, &#39; 3 - 4&#39;, &#39; 5 +&#39;, &#39; no data&#39;), title=&quot;Beaufort sea state&quot;) + tmap::tm_layout(legend.position=c(&#39;left&#39;,&#39;bottom&#39;)) # Show map m_custom2 Add sightings Use the function map_sightings() to add sightings to your map: map_sightings(m, cruz) Customizing sightings To demonstrate some of the customization options, consider this map that shows sightings of false killer whales with custom dot color, shape, and size: map_sightings(m, cruz, include_species = &#39;033&#39;, color_base = &#39;purple&#39;, shape_base = 18, size_base = 1) Next is a map of humpback whales and sperm whales, color-coded by species and shape-coded by whether or not the sighting will be included in the analysis: map_sightings(m, cruz, include_species = c(&#39;076&#39;,&#39;046&#39;), color_code = TRUE, shape_code = TRUE) Here is an overview of the steps needed to map strata, survey tracks, and sightings all together: m &lt;- map_base(&#39;cnp&#39;) m &lt;- map_strata(m, cruz$settings) m &lt;- map_effort(m, cruz) m &lt;- map_sightings(m, cruz, size_base=.4) m "],["summarize.html", " 6 Summarize survey Summariz effort Summarize sightings", " 6 Summarize survey Summariz effort The summarize_effort() functions builds tables with total kilometers and days surveyed. effort_summary &lt;- summarize_effort(cruz, cohort=1, analysis=&#39;density&#39;) This function summarizes effort in three default tables: effort_summary %&gt;% names() [1] &quot;total&quot; &quot;total_by_effort&quot; &quot;total_by_stratum&quot; Total surveyed The slot $total provides the grand total distance and days surveyed: library(DT) effort_summary$total %&gt;% DT::datatable(options=list(initComplete = htmlwidgets::JS( &quot;function(settings, json) {$(this.api().table().container()).css({&#39;font-size&#39;: &#39;9pt&#39;});}&quot;) )) Total surveyed by effort The slot $total_by_effort provides the total distance and days surveyed, grouped by segments that will be included in the analysis and those that won’t: Total surveyed by stratum The slot $total_by_stratum provides the total distance and days surveyed within each stratum, again grouped by segments that will be included in the analysis and those that won’t: Summarize sightings The summarize_sightings() function builds tables summarizing the sightings within each cohort-analysis. (Eventually, we may want to include an option to merge all sightings from all cohort-analyses into a single table.) sightings_summary &lt;- summarize_sightings(cruz, cohort=1, analysis=&#39;density&#39;) This function summarizes sightings in four default tables: sightings_summary %&gt;% names() [1] &quot;simple_totals&quot; &quot;analysis_totals&quot; [3] &quot;stratum_simple_totals&quot; &quot;stratum_analysis_totals&quot; Simple species totals The slot $simple_totals includes all sightings, even if they will not be inluded in analysis: Analysis totals The slot $analysis_totals only includes sightings that meet all inclusion criteria for the analysis: Simple totals for each stratum The slot $stratum_simple_totals splits the first table (simple species totals) so that sightings are tallied for each geo-stratum separately: Analysis totals for each stratum The slot $stratum_analysis_totals splits the second table (analysis totals for each species) so that sightings are tallied for each geo-stratum separately: "],["df.html", " 7 Detection functions Format for Distance", " 7 Detection functions Format for Distance To format the processed data for use in Distance-related analyses, use the function format_distance(). cruz_dist &lt;- format_distance(cruz, cohort=1, analysis=&#39;density&#39;) This function produces a list with four slots: cruz_dist %&gt;% names [1] &quot;cohort&quot; &quot;analysis&quot; &quot;effort&quot; &quot;sightings&quot; The first two slots specify which cohort and analysis these data pertain to. The second two slots, effort and sightings, mirror the format of the EFFORT.csv and SIGHTINGS.csv files produced by ABUND 7/9: Effort Sightings "],["abundance.html", " 8 Abundance estimation", " 8 Abundance estimation Coming soon! "],["casestudies.html", " 9 Central North Pacific", " 9 Central North Pacific To demonstrate what we are building, below is template for quickly running all of the steps detailed in subsequent chapters. This template uses the same data and settings used throughout the vignette: library(swfscDAS) library(LTabundR) library(dplyr) # Settings ===================================================================== # Load strata &amp; study area data(strata_cnp) data(study_cnp) # Survey-wide survey &lt;- load_survey_settings(segment_method = &#39;equallength&#39;, segment_target_km = 30, segment_max_km_gap = 5, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), verbose = TRUE) # Cohort 1 (default) cohort1 &lt;- load_cohort_settings() # Cohort 2 cohort2 &lt;- load_cohort_settings(id=&#39;fkw_insular&#39;, species=33, use_low_if_na = TRUE, truncation_km = 5, strata_overlap_handling = &#39;each&#39;) # Finalize settings settings &lt;- load_settings(strata = strata_cnp, study_area = study_cnp, survey = survey, cohorts=list(cohort1, cohort2)) # Processing =================================================================== # Load &amp; format DAS das_file &lt;- &#39;data/surveys/HICEASwinter2020.das&#39; das &lt;- load_das(das_file) das &lt;- format_das(das, settings) # Process strata cruz &lt;- process_strata(das, settings) # Segmentize cruz &lt;- segmentize(cruz, verbose=TRUE) # Review: segment length distribution hist(cruz$cohorts$default$density$segments$dist, breaks = seq(0,60,by=1), xlab=&#39;Segment lengths (km)&#39;, main=paste0(&#39;Target km: &#39;,settings$survey$segment_target_km)) # Process sightings cruz &lt;- process_sightings(cruz) # Map m &lt;- map_base(&#39;cnp&#39;) m &lt;- map_strata(m, cruz$settings) m &lt;- map_effort(m, cruz) m &lt;- map_sightings(m, cruz, size_base=.4) m "],["california-current-system.html", " 10 California Current System", " 10 California Current System library(swfscDAS) library(LTabundR) library(dplyr) # Settings ===================================================================== # Load strata &amp; study area data(strata_ccs) # Survey-wide survey &lt;- load_survey_settings(segment_method = &#39;equallength&#39;, segment_target_km = 100, segment_max_km_gap = 5, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), verbose = TRUE) # Cohort 1 (default) cohort1 &lt;- load_cohort_settings() # Cohort 2 cohort2 &lt;- load_cohort_settings(id=&#39;beakers&#39;, species=c(1,49,52:59, 61:65, 81:83, 106, 109), use_low_if_na = TRUE, distance_types = c(&#39;S&#39;,&#39;F&#39;,&#39;N&#39;)) # Finalize settings settings &lt;- load_settings(strata = strata_ccs, study_area = NULL, survey = survey, cohorts=list(cohort1, cohort2)) # Processing =================================================================== # Load DAS &amp; subset to a single cruise das_file &lt;- &#39;data/surveys/CAORWA_91-09.das&#39; das &lt;- load_das(das_file) das &lt;- das %&gt;% filter(Cruise == 1635) # Format DAS data for LTabundR das &lt;- format_das(das, settings) # Process strata cruz &lt;- process_strata(das, settings) # Segmentize cruz &lt;- segmentize(cruz, verbose=TRUE) # Review: segment length distribution kms &lt;- cruz$cohorts$default$density$segments$dist hist(kms, breaks = seq(0,1.1*max(kms),by=1), xlab=&#39;Segment lengths (km)&#39;, main=paste0(&#39;Target km: &#39;,settings$survey$segment_target_km)) # Process sightings cruz &lt;- process_sightings(cruz) # Map m &lt;- map_base(&#39;ccs&#39;) m &lt;- map_strata(m, cruz$settings) m &lt;- map_effort(m, cruz) m &lt;- map_sightings(m, cruz, size_base=.4) m "],["eastern-tropical-pacific.html", " 11 Eastern Tropical Pacific", " 11 Eastern Tropical Pacific Coming soon! "],["practicalities.html", " 12 Practicalities", " 12 Practicalities Reproducibility &amp; project management One of the features of the ABUND framework we need to retain is that each analysis is self-contained and reproducible. The folder for an analysis must have all the files and data needed for someone else to be able to replicate it. In the R package framework we are developing, the contents of a project folder will be straightforward (once the code base is bundled into a package). Contents of a project folder: DAS file(s) with survey data Stratum and study area polygon(s), as csv(s) (optional) Group size calibration files (optional) An analysis.R file (or perhaps a .Rmd), containing an adaptation of the code provided in the template above. This script will contain project-specific settings (e.g., the load_settings() call), which allow for the script to be reproducible. "],["stratagallery.html", " 13 Strata gallery Central North Pacific California Current ETP", " 13 Strata gallery This packages comes with several built-in datasets of geographic strata that are commonly used in NOAA/NMFS surveys. The functions strata_explore() and strata_select() were developed to help you explore those built-in options. Central North Pacific strata_explore(&#39;cnp&#39;) To acquire the filepath to one of these strata, pass the index (or indices) printed in the map titles above to the function strata_select(): strata &lt;- strata_select(selections = c(1,3), region = &#39;cnp&#39;) This function returns a named list that can be passed directly to the strata argument in load_settings(). strata %&gt;% names [1] &quot;HI_EEZ&quot; &quot;OtherCNP&quot; The second slot, $paths, contains the filepaths you would need to pass to the load_settings() function. California Current strata_explore(&#39;ccs&#39;) ETP strata_explore(&#39;etp&#39;) "],["segmentizing.html", " 14 Segmentizing Approach Defaults Day vs Equal Length Contiguous vs. non-contiguous effort Segment remainder handling Typical settings", " 14 Segmentizing The package’s segmentize() function and its associated settings were designed to give researchers full control over how data are segmented, be it for design-based density analysis (which tend to use long segments of 100 km or more and allow for non-contiguous effort to be included in the same segment) or for habitat modeling (which tend to use short segments of 5 - 10 km and disallow non-contiguous effort to be pooled into the same segment). Approach Segments are built and stored separately for each cohort of species, since each cohort has specific settings for segmentizing. Within each cohort, two different sets of segments may be built, in the event that any of the cohort-specific settings for detection function estimation (distance_types, distance_modes, and distance_on_off) are different from the settings for density estimation (density_types, density_modes, and density_on_off). When that happens, each cohort will have two lists, one for each analysis: a slot for density segments and their derivated datasets, and a slot for distance segments and derivative data. Within each cohort-analysis, the survey is first grouped into “blocs” of data that all share the same “effort scenario”, i.e., all rows share the same Cruise number, study area status (in or out), geographic stratum, and year. Since a survey may leave a stratum then return to it many days hence, it is normal for these blocs to contain non-contiguous data with large spatial gaps. These gaps will be addressed a few steps down. The blocs are split further according to survey-wide and cohort-specific settings; for example, if segment_type_handling input is \"separate\", then data with EffType = \"S\" will all belong in its own block, and data with EffType = \"N\" will belong in its own bloc, etc. The blocs are split a final time according to whether the effort scenario meets inclusion criteria for the analysis. These inclusion criteria are controlled by the cohort-specific settings such as density_types, density_modes, and density_in_off. Rows of data that meet the inclusion criteria are relegated to their own data bloc, and given a new column, use, with the value TRUE. Data that do not meet the criteria are relegated to their own bloc as well (column use is FALSE). This means that, at the end of this process, we will have segments that will be used in the density/detection function analysis, and segments that will not. (The excluded segments are not deleted or transformed in any other way; they can still be used in summarizing detections, etc.) Next, the segmentize() function loops through each of these blocs of effort and parses its data into segments according to the segment_method. If segmentizing by \"day\", this is straightforward: all data occurring on a unique date are assigned to its own segment. Segmentizing by \"equallength\" is a bit more complicated in terms of coding: segments are built up one line of data at a time; if the segment_target_km is reached or the segment_max_interval is exceeded, a new segment is begun. At the end of this process, you have lists of data sorted into their segments, each with a unique seg_id, as well as a summary dataframe that provides the distance (km); time and coordinates for the beginning, middle, and end of the segment; and the weighted averages of sighting conditions and weather data contained in the segment. Setting up this demo The demonstration of segmentize() on in Processing chapter relies on the settings list that is attached as a slot in the cruz object. But you can override those settings with direct function inputs in segmentize(), which gives us a chance to explore segmentization options. First we load the demo data and carry out initial processing: data(settings) das_file &lt;- &#39;data/surveys/HICEASwinter2020.das&#39; das &lt;- load_das(das_file, perform_checks = FALSE, print_glimpse = FALSE) das &lt;- format_das(das, settings) cruz &lt;- process_strata(das, settings, verbose=FALSE) And this is the histogram function we will be using to display the results of each run of segmentize(): segment_histogram &lt;- function(cohort_effort, by_day=FALSE){ segs &lt;- cohort_effort$segments segmax &lt;- max(segs$dist,na.rm=TRUE)*1.1 if(by_day){ main_use &lt;- paste0(&#39;Segments (use) | by day&#39;) main_exclude &lt;- paste0(&#39;Segments (exclude) | by day&#39;) }else{ main_use &lt;- paste0(&#39;Segments (use) | target: &#39;,settings$survey$segment_target_km,&#39; km&#39;) main_exclude &lt;- paste0(&#39;Segments (exclude) | target: &#39;,settings$survey$segment_target_km,&#39; km&#39;) } par(mfrow=c(1,2)) par(mar=c(4.2,4.2,2.5,.5)) hist(segs$dist[segs$use], breaks = seq(0,segmax,by=segmax/40), xlab=&#39;Segment lengths (km)&#39;, main=main_use, cex.main = .8, cex.axis = .8, cex.lab = .8) hist(segs$dist[!segs$use], breaks = seq(0,segmax,by=segmax/40), xlab=&#39;Segment lengths (km)&#39;, main=main_exclude, cex.main = .8, cex.axis = .8, cex.lab = .8) par(mfrow=c(1,1)) } Defaults Here is the segmentize() function parameterized with the “factory default” settings from load_settings(). cruz_demo &lt;- segmentize(cruz, segment_method = &#39;equallength&#39;, segment_target_km = 30, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), density_types = c(&#39;S&#39;,&#39;F&#39;), density_modes = c(&#39;P&#39;,&#39;C&#39;), density_on_off = c(TRUE), distance_types = NULL, distance_modes = NULL, distance_on_off = NULL, random_seed = NULL) Error: Must group by variables found in `.data`. * Column `study_area` is not found. # Number of segments cruz_demo$cohorts$default$density$segments %&gt;% nrow Error in nrow(.): object &#39;cruz_demo&#39; not found # Plot segment_histogram(cruz_demo$cohorts$default$density) Error in segment_histogram(cruz_demo$cohorts$default$density): object &#39;cruz_demo&#39; not found Day vs Equal Length By day cruz_demo &lt;- segmentize(cruz, segment_method = &#39;day&#39;, segment_target_km = 30, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), density_types = c(&#39;S&#39;,&#39;F&#39;), density_modes = c(&#39;P&#39;,&#39;C&#39;), density_on_off = c(TRUE), distance_types = NULL, distance_modes = NULL, distance_on_off = NULL, random_seed = NULL) Error: Must group by variables found in `.data`. * Column `study_area` is not found. # Number of segments cruz_demo$cohorts$default$density$segments %&gt;% nrow Error in nrow(.): object &#39;cruz_demo&#39; not found # Plot segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE) Error in segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE): object &#39;cruz_demo&#39; not found By target length of 150 km cruz_demo &lt;- segmentize(cruz, segment_method = &#39;equallength&#39;, segment_target_km = 150, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), density_types = c(&#39;S&#39;,&#39;F&#39;), density_modes = c(&#39;P&#39;,&#39;C&#39;), density_on_off = c(TRUE), distance_types = NULL, distance_modes = NULL, distance_on_off = NULL, random_seed = NULL) Error: Must group by variables found in `.data`. * Column `study_area` is not found. # Number of segments cruz_demo$cohorts$default$density$segments %&gt;% nrow Error in nrow(.): object &#39;cruz_demo&#39; not found # Plot segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE) Error in segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE): object &#39;cruz_demo&#39; not found Contiguous vs. non-contiguous effort The example above allows for non-contiguous effort; a segment is allowed to contain effort separated by gaps as large as 24 hours (settings$max_interval). To coerce segments to represent only contiguous effort, make that setting very small: cruz_demo &lt;- segmentize(cruz, segment_method = &#39;equallength&#39;, segment_target_km = 30, segment_max_interval = .1, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), density_types = c(&#39;S&#39;,&#39;F&#39;), density_modes = c(&#39;P&#39;,&#39;C&#39;), density_on_off = c(TRUE), distance_types = NULL, distance_modes = NULL, distance_on_off = NULL, random_seed = NULL) Error: Must group by variables found in `.data`. * Column `study_area` is not found. # Number of segments cruz_demo$cohorts$default$density$segments %&gt;% nrow Error in nrow(.): object &#39;cruz_demo&#39; not found # Plot segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE) Error in segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE): object &#39;cruz_demo&#39; not found You can see that many contiguous periods of effort were much shorter than the target length of 30 km. This is why allowing for non-contiguous effort can be advantageous for target segment lengths larger than 5 - 10 km. Segment remainder handling The default setting for segment_remainder_handling, c('append','segment'), means that remainders less than half the target length will be randomly appended to another segment, while remainders more than half will be treated as their own segment (and will be placed randomly along the trackline). If you don’t want that level of complexity, you can simply assign a single setting: 'append' will append the remainder in all cases, regardless of remainder length relative to the target length. The same idea goes for 'segment'. The other possible setting is 'disperse', which disperses the remainder evenly across all segments. To demonstrate, let’s use a target length of 100 km. cruz_demo &lt;- segmentize(cruz, segment_method = &#39;equallength&#39;, segment_target_km = 100, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;disperse&#39;), density_types = c(&#39;S&#39;,&#39;F&#39;), density_modes = c(&#39;P&#39;,&#39;C&#39;), density_on_off = c(TRUE), distance_types = NULL, distance_modes = NULL, distance_on_off = NULL, random_seed = NULL) Error: Must group by variables found in `.data`. * Column `study_area` is not found. # Number of segments cruz_demo$cohorts$default$density$segments %&gt;% nrow Error in nrow(.): object &#39;cruz_demo&#39; not found # Plot segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE) Error in segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE): object &#39;cruz_demo&#39; not found Note that most segments are longer than the target length, due to the impact of dispersing the remainder. If you wanted, you could combat this by making the target length slightly smaller: cruz_demo &lt;- segmentize(cruz, segment_method = &#39;equallength&#39;, segment_target_km = 90, segment_max_interval = 48, segment_type_handling = &#39;separate&#39;, segment_remainder_handling = c(&#39;disperse&#39;), density_types = c(&#39;S&#39;,&#39;F&#39;), density_modes = c(&#39;P&#39;,&#39;C&#39;), density_on_off = c(TRUE), distance_types = NULL, distance_modes = NULL, distance_on_off = NULL, random_seed = NULL) Error: Must group by variables found in `.data`. * Column `study_area` is not found. # Number of segments cruz_demo$cohorts$default$density$segments %&gt;% nrow Error in nrow(.): object &#39;cruz_demo&#39; not found # Plot segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE) Error in segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE): object &#39;cruz_demo&#39; not found But in general, the disperse option may be more appropriate for shorter segment lengths. Typical settings Design-based line transect analysis To replicate methods used in density estimation analyses, use large segment lengths (100 km or more) or simply segmentize by day, with S and F effort types kept separate. (See the examples above.) Remember that long segment lengths won’t work well unless you allow for non-contiguous effort. Habitat modeling To replicate the methods used in typical habitat modeling studies, use smaller segment lengths of contiguous effort. In these studies it may be acceptable to pool various effort types into the same segments. cruz_demo &lt;- segmentize(cruz, segment_method = &#39;equallength&#39;, segment_target_km = 5, segment_max_interval = .1, segment_type_handling = &#39;pool&#39;, segment_remainder_handling = c(&#39;append&#39;,&#39;segment&#39;), density_types = c(&#39;S&#39;,&#39;F&#39;), density_modes = c(&#39;P&#39;,&#39;C&#39;), density_on_off = c(TRUE), distance_types = NULL, distance_modes = NULL, distance_on_off = NULL, random_seed = NULL) Error: Must group by variables found in `.data`. * Column `study_area` is not found. # Number of segments cruz_demo$cohorts$default$density$segments %&gt;% nrow Error in nrow(.): object &#39;cruz_demo&#39; not found # Plot segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE) Error in segment_histogram(cruz_demo$cohorts$default$density, by_day = TRUE): object &#39;cruz_demo&#39; not found "],["misc_functions.html", " 15 Miscellaneous functions", " 15 Miscellaneous functions species_translator() To streamline the management of species codes, scientific names, common names, etc., in the functions throughout this package, we have developed a “translator” function that returns the various identifiers for a species according to a variety of search terms. You can search by species code: # source(&#39;R/species_translator.R`) species_translator(id = &#39;035&#39;) %&gt;% t() 35 code &quot;035&quot; short_name &quot;LONG_PILOT&quot; scientific_name &quot;Globicephala melas&quot; common_name1 &quot;Long-finned pilot whale&quot; common_name2 &quot; Atlantic pilot whale&quot; common_name3 &quot; blackfish&quot; common_name4 &quot; pothead&quot; By the short code name: species_translator(id = &#39;LONG_PILOT&#39;) %&gt;% t() 35 code &quot;035&quot; short_name &quot;LONG_PILOT&quot; scientific_name &quot;Globicephala melas&quot; common_name1 &quot;Long-finned pilot whale&quot; common_name2 &quot; Atlantic pilot whale&quot; common_name3 &quot; blackfish&quot; common_name4 &quot; pothead&quot; By the scientific name: species_translator(id = &#39;Globicephala melas&#39;) %&gt;% t() 35 code &quot;035&quot; short_name &quot;LONG_PILOT&quot; scientific_name &quot;Globicephala melas&quot; common_name1 &quot;Long-finned pilot whale&quot; common_name2 &quot; Atlantic pilot whale&quot; common_name3 &quot; blackfish&quot; common_name4 &quot; pothead&quot; Or by one of the species’ common names: species_translator(id = &#39;Long-finned pilot whale&#39;) %&gt;% t() 35 code &quot;035&quot; short_name &quot;LONG_PILOT&quot; scientific_name &quot;Globicephala melas&quot; common_name1 &quot;Long-finned pilot whale&quot; common_name2 &quot; Atlantic pilot whale&quot; common_name3 &quot; blackfish&quot; common_name4 &quot; pothead&quot; The function will return any species for which there is a partial match: species_translator(id = &#39;megap&#39;) %&gt;% t() 76 code &quot;076&quot; short_name &quot;HUMPBACK_W&quot; scientific_name &quot;Megaptera novaeangliae&quot; common_name1 &quot;Humpback whale&quot; common_name2 &quot;&quot; common_name3 &quot;&quot; common_name4 &quot;&quot; species_translator(id = &#39;killer&#39;) code short_name scientific_name common_name1 32 032 PYGMY_KLLR Feresa attenuata Pygmy killer whale 33 033 FALSE_KLLR Pseudorca crassidens False killer whale 37 037 KILLER_WHA Orcinus orca Killer whale 110 110 Orcinus orca Transient killer whale 111 111 Orcinus orca Resident killer whale 112 112 Orcinus orca Offshore killer whale 113 113 Orcinus orca Type A Antarctic killer whale 114 114 Orcinus orca Type B Antarctic killer whale 115 115 Orcinus orca Type C Antarctic killer whale common_name2 common_name3 common_name4 32 slender blackfish 33 37 110 111 112 113 114 115 Note that if species_codes is NULL, as in the examples above, the list of codes used in ABUND9 will be used as a default. species_manifest() Inventory the species observed: species_manifest &lt;- species_inventory(cruz) Check out result: species_manifest[,c(1,2,5)] "],["backlog.html", " 16 Appendix: Backlog", " 16 Appendix: Backlog Fix polygon area estimation! (Currently does not subtract land area! Ack!) Handle probable species in process_sightings(). Probable species currently are not handled in process_sightings(): I need a dataset that has a probable event in order to code. Look for it in the CCS data. Check to make sure that you have added geometric mean option in process_sightings(), even if geometric WEIGHTED mean is not possible. Main Islands map bbox Map bbox for SoCal, Central Cal, and northern CCS Add Survey summary function / section to this Rmd Figure out which ETP strata to have as defaults for both survey strata and study area polygons (there are like 100 in the folder Jeff sent us). May be a question for Tim G. Test this code on lots of cruise data files to establish basic functionality for Hawaii, California Current, and ETP. Troubleshoot why longitudes are not displayed on Hawaii base map Accommodate subgroup settings for FKW analyses Close comparison to FORTRAN outputs Onward into next stages of Data Processing milestones Method for stratifying by Beaufort. study_area_explore() and study_area_select(). "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
