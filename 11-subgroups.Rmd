# Subgroup-based analysis

```{r, echo=FALSE, eval=TRUE, collapse=TRUE, include=TRUE, warning=FALSE, message=FALSE}
library(dplyr)
library(magrittr)
library(LTabundR)

rerun_from_scratch <- FALSE
# If you want to confirm the package works, change to TRUE.
# If you already know it does, change to FALSE so that knitting is quick
# (it will use saved R objects instead of producing them anew)
```

False killer whales (*Pseudorca crassidens*) are rare and occur in dispersed subgroups, which complicates conventional distance sampling approaches to line-transect analysis. To better estimate their abundance, in 2010 the Pacific Islands Fisheries Science Center (PIFSC) initiated a sub-group protocol referred to as the "PC Protocol", a reference to the species' scientific name.

To conduct line-transect analysis with this sub-group-based protocol, a method was developed in 2014 - 2017
To handle this, a separate, *subgroup-based* analytical approach was developed in 2014 - 2017, then updated in 2020 ([Bradford et al. 2020](https://www.fisheries.noaa.gov/inport/item/59592)). 

An additional complication is that false killer whales in Hawaiian waters belong to two discrete populations -- the Northwest Hawaiian Islands (NWHI) population and a pelagic population -- whose ranges partially overlap, which means that population assignment cannot always be based simply on the geographic location of sightings. When geographic inference of population is not possible, biopsy-sampled genetics, photo-identification, and acoustics are used to assign each sighting to a population *post-hoc*.  

To accommodate these special circumstances with an appropriate balance of flexibility and efficiency, `LTabundR` includes a function named `lta_subgroup()`, whose use will look something like this: 

```{r, echo=TRUE, eval=FALSE, collapse=TRUE, message=FALSE, warning=FALSE}
lta_subgroup(df_sits,
             truncation_distance,
             ss,
             cruz10,
             g0_spp,
             g0_truncation,
             g0_pool_bft,
             g0_jackknife_fraction = 0.1,
             density_segments,
             density_das,
             density_sightings,
             abundance_area,
             iterations = 1000,
             output_dir = '../test_code/subgroup/',
             toplot = TRUE,
             verbose = TRUE,
             density_bootstraps = 10000)
```

We will step through each of these inputs below, using a case study in which we estimate false killer whale abundance in the Hawaiian EEZ for 2017. 

## Inputs {-}  

### `df_sits` {-}  

This is a `data.frame` of sightings you want to use to fit the detection function model. For false killer whales in Bradford et al. (2020), this is a combination of systematic sightings prior to 2010 and Phase 1 sightings from 2010 onwards (using the PC protocol). No filtering will be applied to these sightings within this function, so make sure you provide the data pre-filtered. Bradford et al. (2020) used a single detection function for all populations of false killer whale. 

`LTabundR` has a built-in dataset for processed Central North Pacific surveys, 1986-2020, using 150-km segments. We will use that here: 

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
data("cnp_150km_1986_2020")
cruz <- cnp_150km_1986_2020
```

The code used to generate this dataset can be seen by pulling up the help documentation: `?noaa_10km_1986_2020`.  

As mentioned above, for 1986 - 2010, all detections are assumed to be 'Phase 1' sightings, and therefore usable in detection function estimation. Here we draw those sightings from the above `cruz` object, filtering as needed (the species code for false killer whales is `"033"`), and to simplify we will select only a few key columns.   

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
sits1  <-
  cruz$cohorts$all$sightings %>%
  filter(OnEffort == TRUE,
         year < 2011,
         Lat >= 5, Lat <= 40, Lon >= -185, Lon <= -120,
         species == '033',
         mixed == FALSE) %>%
  select(DateTime, Lat, Lon, Cruise, PerpDistKm)

sits1 %>% nrow

sits1 %>% head
```

For 2011 onwards, we will use Phase 1 subgroup detections from the PC protocol, making sure that the column holding detection distances is named `PerpDistKm`:    

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
sits2  <-
  cruz$cohorts$all$subgroups$subgroups %>%
  filter(OnEffort == TRUE,
         lubridate::year(DateTime) >= 2011,
         Lat >= 5, Lat <= 40, Lon >= -185, Lon <= -120,
         Species == '033',
         Phase == 1) %>%
  select(DateTime, Lat, Lon, Cruise, PerpDistKm = PerpDist)

sits2 %>% nrow

sits1 %>% head
```

To create `df_sits` for detection function fitting, we combine these datasets together:  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
df_sits <- rbind(sits1, sits2)

df_sits %>% nrow
```

### `truncation_distance` {-}  

The truncation distance, in km, will be applied during detection function model fitting. Typically the farthest 5 - 10% of sightings are truncated, but this needs to be balanced by sample size considerations.  

Get candidate distances:  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE, fig.height=4, fig.width=7}
truncation_options <- quantile(df_sits$PerpDistKm, 
                               c(0.90,0.91,0.92,0.93,0.94,.95))

truncation_options
```

Plot these options:  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE, fig.height=4, fig.width=7}
hist(df_sits$PerpDistKm, main='Detection distances')
abline(v=truncation_options, col='red', lty=3)
```

Get sample size remaining for each candidate distance:  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE, fig.height=4, fig.width=7}
data.frame(km = truncation_options, 
           n = sapply(truncation_options, 
                      function(x){length(which(df_sits$PerpDistKm <= x))}))
```

Based on these results, we will choose a truncation distance of 4.5 km. 

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
truncation_distance <- 4.5
```

### `ss` {-}  

This is a numeric vector of subgroup school sizes. The function will find this vector's geometric mean and bootstrapped CV. In Bradford et al. (2020), school size data come from all Phase 1 and Phase 2 estimates of subgroup sizes from 2010 onwards. In the processed `cruz` object, each of those estimates is the geometric mean of repeat estimates from separate observers.  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
ss  <-
  cruz$cohort$all$subgroups$subgroups %>%
  filter(lubridate::year(DateTime) >= 2011,
         Lat >= 5, Lat <= 40, Lon >= -185, Lon <= -120,
         Species == '033') %>%
  pull(GSBest_geom)
  
ss %>% length

ss
```

### `cruz10` {-}  

This is a processed `cruz` object with short segment lengths, ideally 10 km or less (hence the 10 in the input name). This `cruz` object will be used to estimate *Rg(0)*, i.e., the relative trackline detection probability (see its chapter). `LTabundR` comes with a built-in dataset we can use for this purpose:  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
data("noaa_10km_1986_2020")
cruz10 <- noaa_10km_1986_2020
```

The code used to generate this dataset can be seen by pulling up the help documentation: `?noaa_10km_1986_2020`.  

### `g0_spp` {-}  

This is a character vector of species code(s) to use to estimate *Rg(0)*. In most cases this will be a single species, e.g., `"033"` for false killer whales.  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
g0_spp <- '033'
```

### `g0_truncation` {-}  

The truncation distance to use when estimating Rg(0). In Bradford et al. (2020) this is 5.5 km.  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
g0_truncation <- 5.5
```

### `g0_pool_bft` {-}  

A way to specify that low Beaufort sea states, which are typically rare in open-ocean surveys, should be pooled. This step may be needed in order to achieve a monotonic decline in the *g(0)* ~ Bft relationship, but the default is `NULL`, i.e., no pooling. If `g0_pool_bft` is the character string `"01"`, Beaufort states 1 will be pooled into state 0. If `g0_pool_bft` is the character string `"012"`, Beaufort states 1 and 2 will be pooled into state 0.  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
g0_pool_bft = NULL
```

### `g0_jackknife_fraction` {-}  

The proportion of data to leave out within each jackknife permutation. The default is `0.1` (i.e., 10% of the data, yielding 10 jackknife loops), after Barlow (2015).  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
g0_jackknife_fraction = 0.1
```

### `density_segments` {-}  

The survey segments to be used in density/abundance estimation. For example, Bradford et al. (2020) used 150-km segments to estimate false killer whale density in the Hawaiian EEZ in 2017. For this we can use the 1986-2020 dataset we loaded above. Note that no filtering will be applied to these segments by the `lta_subgroup()` function, so w need to filter them ourselves first: we want only systematic segments for the Hawaiian EEZ in 2017 (specially, just cruises 1705 and 1706).  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
cruzi <- filter_cruz(cruz = cruz,
                      analysis_only = TRUE,
                      years = 2017,
                      cruises = c(1705, 1706),
                      regions = 'HI_EEZ',
                      bft_range = 0:6,
                      eff_types = 'S',
                      on_off = TRUE)
```

From this filtered cruz object, we will isolate the segments data:  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
density_segments <- cruzi$cohorts$all$segments
```

Since we do not want to stratify our analysis by smaller geostrata, such as the Main Hawaiian Islands, we will go ahead and coerce all stratum assignments to the Hawaiian EEZ geostratum:  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
density_segments$stratum <- 'HI_EEZ'
```

### `density_das` {-}  

This is the complete survey data corresponding to the above segments. These data will be used to determine the proportion of survey effort occurring in each Beaufort sea state during estimation of *Relative g(0)*.  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
density_das <- cruzi$cohorts$all$das
```

### `density_sightings` {-}  

These are the encounters to use in density/abundance estimation. In Bradford et al. (20120), these were the Phase 1 detections of false killer whale subgroups within the population-region-year of interest, e.g., Northwest Hawaiian Island population sightings within the Hawaiian EEZ in 2017. No filtering is applied to these sightings within `lta_subgroups()`, so make sure only the sightings you wish to use are included and nothing more.  

In this example, since we do not have population information on hand, we will not filter detections to a specific population. Instead, we will estimate abundance of all false killer whales within the Hawaiian EEZ: 

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
density_sightings  <-
  cruz$cohorts$all$subgroups$subgroups %>%
  filter(EffType == 'S',
         OnEffort == TRUE,
         lubridate::year(DateTime) == 2017,
         PerpDist <= truncation_distance,
         Species == '033',
         Phase == 1)

density_sightings %>% nrow

density_sightings %>% head
```

As above, let's make sure the geostratum assignments for these sightings are simple: 


```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
density_segments$stratum <- 'HI_EEZ'
```

### `abundance_area` {-}  

This is the area, in square km, of the region of interest. The density estimate will be scaled by this area.  

We have two options for finding this area. The first is to draw the area from our `cohort$strata` slot:   

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
cruz$strata$area[cruz$strata$stratum == 'HI_EEZ']
```

The second is to calculate it ourselves using the `LTabundR` function `strata_area()`. This second option will be useful if your study area is a complicated combination/substraction of multiple geostrata.  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE, fig.height=7, fig.width=7}
data(strata_cnp)

abundance_area <- 
  strata_area(strata_all = strata_cnp,
              strata_keep = 'HI_EEZ')$km2

abundance_area
```

### Remaining inputs {-}  

**`iterations`**: Number of iterations to use in the various CV bootstrapping procedures occurring throughout this function, specifically: Effective Strip Half-Width CV estimation, school size CV estimation, weighted g(0) CV estimation, and encounter rate estimation.  

**`output_dir`**: The path in which results RData files should be stored. If left "", the current working directory will be used.  

**`toplot`**: A Boolean, with default FALSE, indicating whether to plot various aspects of the analysis.  

**`verbose`**: A Boolean, with default TRUE, indicating whether to print status updates to the Console.  

**`density_bootstraps`**: Number of bootstrap iterations to use for the CV estimate of density and abundance specifically. This input allows this final step to use a different (typically larger) iteration size than the iterations input above.  

```{r, echo=FALSE, eval=rerun_from_scratch, collapse=TRUE, message=FALSE, warning=FALSE}
results_subgroup <- 
  lta_subgroup(df_sits,
             truncation_distance,
             ss,
             cruz10,
             g0_spp,
             g0_truncation,
             g0_pool_bft,
             g0_jackknife_fraction = 0.1,
             density_segments,
             density_das,
             density_sightings,
             abundance_area,
             iterations = 10,
             output_dir = 'subgroup/',
             toplot = TRUE,
             verbose = TRUE,
             density_bootstraps = 10000)
```


```{r, echo=TRUE, eval=rerun_from_scratch, collapse=TRUE, message=FALSE, warning=FALSE}
save(results_subgroup, file='results_subgroup.RData')
```

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
load('results_subgroup.RData')
```


## Outputs {-}  

The function returns a `list` with many slots, including estimates of density and abundance – along with estimates of intermediate parameters – with a CV derived from a bootstrapping routine. To demonstrate this output, we will use results from a call with only 10 bootstrap iterations.  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
results_subgroup %>% names
```

Most of these slots hold best-estimates of parameters or sample size details:  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
results_subgroup[c(1:15, 19:20)]
```

The `g0_details` slot includes the results from the `g0_model()` and `g0_weighted()` functions called internally by `lta_subgroup()`. See those functions' documentation pages for details.  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
results_subgroup$g0_details %>% names
```

The `df` slot includes details of the detection function fit. See the documentation for `df_plot()` for details.  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
results_subgroup$df %>% names
```

The `bootstraps` slot has the bootstrapped values for various parameters, in case they are useful for troubleshooting, subsequent analyses, and/or plotting:  

```{r, echo=TRUE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE}
results_subgroup$bootstraps %>% names
```

Some examples:  

```{r, echo=FALSE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE, fig.height=4, fig.width=7}
results_subgroup$bootstraps$g0 %>% hist(main='g(0) bootstraps')
```

```{r, echo=FALSE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE, fig.height=4, fig.width=7}
results_subgroup$bootstraps$D %>% hist(main='Density bootstraps')
```

```{r, echo=FALSE, eval=TRUE, collapse=TRUE, message=FALSE, warning=FALSE, fig.height=4, fig.width=7}
results_subgroup$bootstraps$N %>% hist(main='Abundance bootstraps')
```

## Behind the scenes {-}  

This function performs the following operations:

1. Fits a detection function to `df_sits` without covariates, using the `LTabundR` function `df_fit()`, in order to estimate the effective strip half-width (ESW).  

2. Conducts bootstrap re-sampling of the detection function fitting routine in order to estimate the CV of ESW.  

3. Estimates the geometric mean of subgroup school size based on the `ss` input.  

4. Creates a bootstrap-resampled distribution of subgroup school sizes, with which CV is estimated.  

5. Models the *Relative g(0)* in different survey conditions using the `LTabundR` function `g0_model()`. This function also estimates the CV of the *Rg(0)* estimate in each Beaufort sea state using jackknife resampling.  

6. Estimates the encounter rate (subgroup detections / trackline surveyed).  

7. Creates a bootstrap-resampled distribution of encounter rate estimates.  

8. Calculates a weighted *g(0)* estimate according to the proportion of effort occurring in each Beaufort sea state, then uses an automated parameter optimization routine (see details in `LTabundR` function `g0_weighted()`) to estimate the CV of the weighted *g(0)* estimate.  

9. Creates a bootstrap-resampled distribution of the weighted *g(0)* estimate.  

10. Estimates density using the best estimates of effective strip half-width, school size, *g(0)*, and the encounter rate.  

11. Estimates abundance by scaling the density estimate by the provided abundance_area.  

12. Creates a bootstrap-resampled distribution of the density estimate by iteratively drawing values from the resampled distributions of the constituent parameters of the density equation.  

13. Creates a bootstrap-resampled distribtion of the abundance estimate by scaling the density distribution by abundance_area.  


Note that this approach could theoretically be used for other species that occur in subgroups.

